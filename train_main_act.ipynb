{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4a317ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T02:41:54.582847Z",
     "iopub.status.busy": "2024-12-08T02:41:54.581858Z",
     "iopub.status.idle": "2024-12-08T02:42:04.092176Z",
     "shell.execute_reply": "2024-12-08T02:42:04.091159Z"
    },
    "papermill": {
     "duration": 9.516137,
     "end_time": "2024-12-08T02:42:04.094135",
     "exception": false,
     "start_time": "2024-12-08T02:41:54.577998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\r\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: einops\r\n",
      "Successfully installed einops-0.8.0\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch==2.5.0 torchvision==0.20.0 torchaudio==2.5.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "# !pip install tqdm\n",
    "# !pip install matplotlib \n",
    "# !pip install plotly\n",
    "# !pip install pandas\n",
    "# !pip install wandb\n",
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c96d1b6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-08T02:42:04.101428Z",
     "iopub.status.busy": "2024-12-08T02:42:04.101141Z",
     "iopub.status.idle": "2024-12-08T02:42:11.262559Z",
     "shell.execute_reply": "2024-12-08T02:42:11.261898Z"
    },
    "papermill": {
     "duration": 7.167498,
     "end_time": "2024-12-08T02:42:11.264557",
     "exception": false,
     "start_time": "2024-12-08T02:42:04.097059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# adapted from https://colab.research.google.com/drive/1F6_1_cWXE5M7WocUcpQWp3v8z4b1jL20 (https://arxiv.org/abs/2301.05217), thanks!\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "import tqdm\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"colab\"\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from functools import *\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "# import comet_ml\n",
    "import wandb\n",
    "import itertools\n",
    "\n",
    "# find path of the project from the script\n",
    "root_path = '/kaggle/working'\n",
    "# from analysis.utils import extract_embeddings\n",
    "wandb.login(key='2b1626edceae9b68a67d66923587da64398da02c')\n",
    "class HookPoint(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fwd_hooks = []\n",
    "        self.bwd_hooks = []\n",
    "    def give_name(self, name):\n",
    "        self.name = name\n",
    "    def add_hook(self, hook, dir='fwd'):\n",
    "        def full_hook(module, module_input, module_output):\n",
    "            return hook(module_output, name=self.name)\n",
    "        if dir=='fwd':\n",
    "            handle = self.register_forward_hook(full_hook)\n",
    "            self.fwd_hooks.append(handle)\n",
    "        elif dir=='bwd':\n",
    "            handle = self.register_backward_hook(full_hook)\n",
    "            self.bwd_hooks.append(handle)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid direction {dir}\")\n",
    "    def remove_hooks(self, dir='fwd'):\n",
    "        if (dir=='fwd') or (dir=='both'):\n",
    "            for hook in self.fwd_hooks:\n",
    "                hook.remove()\n",
    "            self.fwd_hooks = []\n",
    "        if (dir=='bwd') or (dir=='both'):\n",
    "            for hook in self.bwd_hooks:\n",
    "                hook.remove()\n",
    "            self.bwd_hooks = []\n",
    "        if dir not in ['fwd', 'bwd', 'both']:\n",
    "            raise ValueError(f\"Invalid direction {dir}\")\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class Embed(nn.Module):\n",
    "    def __init__(self, d_vocab, d_model):\n",
    "        super().__init__()\n",
    "        self.W_E = nn.Parameter(torch.randn(d_model, d_vocab)/np.sqrt(d_model))\n",
    "    def forward(self, x):\n",
    "        return torch.einsum('dbp -> bpd', self.W_E[:, x])\n",
    "\n",
    "class Unembed(nn.Module):\n",
    "    def __init__(self, d_vocab, d_model):\n",
    "        super().__init__()\n",
    "        self.W_U = nn.Parameter(torch.randn(d_model, d_vocab)/np.sqrt(d_vocab))\n",
    "    def forward(self, x):\n",
    "        return (x @ self.W_U)\n",
    "\n",
    "# Positional Embeddings\n",
    "class PosEmbed(nn.Module):\n",
    "    def __init__(self, max_ctx, d_model):\n",
    "        super().__init__()\n",
    "        self.W_pos = nn.Parameter(torch.randn(max_ctx, d_model)/np.sqrt(d_model))\n",
    "    def forward(self, x):\n",
    "        return x+self.W_pos[:x.shape[-2]]\n",
    "\n",
    "# Attention\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_head, n_ctx, attn_coeff):\n",
    "        super().__init__()\n",
    "        self.W_K = nn.Parameter(torch.randn(num_heads, d_head, d_model)/np.sqrt(d_model))\n",
    "        self.W_Q = nn.Parameter(torch.randn(num_heads, d_head, d_model)/np.sqrt(d_model))\n",
    "        self.W_V = nn.Parameter(torch.randn(num_heads, d_head, d_model)/np.sqrt(d_model))\n",
    "        self.W_O = nn.Parameter(torch.randn(d_model, d_head * num_heads)/np.sqrt(d_model))\n",
    "        self.attn_coeff = attn_coeff\n",
    "        self.register_buffer('mask', torch.tril(torch.ones((n_ctx, n_ctx))))\n",
    "        self.d_head = d_head\n",
    "        self.hook_k = HookPoint()\n",
    "        self.hook_q = HookPoint()\n",
    "        self.hook_v = HookPoint()\n",
    "        self.hook_z = HookPoint()\n",
    "        self.hook_attn = HookPoint()\n",
    "        self.hook_attn_pre = HookPoint()\n",
    "\n",
    "    def forward(self, x):\n",
    "        k = self.hook_k(torch.einsum('ihd,bpd->biph', self.W_K, x))\n",
    "        q = self.hook_q(torch.einsum('ihd,bpd->biph', self.W_Q, x))\n",
    "        v = self.hook_v(torch.einsum('ihd,bpd->biph', self.W_V, x))\n",
    "        attn_scores_pre = torch.einsum('biph,biqh->biqp', k, q)\n",
    "        attn_scores_masked =attn_scores_pre\n",
    "        normalized = self.hook_attn_pre(attn_scores_masked/np.sqrt(self.d_head))\n",
    "        normalized = F.softmax(normalized, dim=-1)\n",
    "        attn_matrix = self.hook_attn(\n",
    "            normalized*self.attn_coeff+(1-self.attn_coeff))\n",
    "        z = self.hook_z(torch.einsum('biph,biqp->biqh', v, attn_matrix))\n",
    "        z_flat = einops.rearrange(z, 'b i q h -> b q (i h)')\n",
    "        out = torch.einsum('df,bqf->bqd', self.W_O, z_flat)\n",
    "        return out\n",
    "\n",
    "# +\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_model, d_mlp, act_type):\n",
    "        super().__init__()\n",
    "        self.W_in = nn.Parameter(torch.randn(d_mlp, d_model)/np.sqrt(d_mlp))\n",
    "        self.b_in = nn.Parameter(torch.zeros(d_mlp))\n",
    "        self.W_out = nn.Parameter(torch.randn(d_model, d_mlp)/np.sqrt(d_model))\n",
    "        self.b_out = nn.Parameter(torch.zeros(d_model))\n",
    "        self.act_type = act_type\n",
    "        # self.ln = LayerNorm(d_mlp, model=self.model)\n",
    "        self.hook_pre = HookPoint()\n",
    "        self.hook_post = HookPoint()\n",
    "        assert act_type in ['ReLU', 'GeLU', 'Tanh']\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hook_pre(torch.einsum('md,bpd->bpm', self.W_in, x) + self.b_in)\n",
    "        if self.act_type=='ReLU':\n",
    "            x = F.relu(x)\n",
    "        elif self.act_type=='GeLU':\n",
    "            x = F.gelu(x)\n",
    "        elif self.act_type=='Tanh':\n",
    "            x = F.tanh(x)\n",
    "        x = self.hook_post(x)\n",
    "#        return x\n",
    "        x = torch.einsum('dm,bpm->bpd', self.W_out, x) + self.b_out\n",
    "        return x\n",
    "\n",
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, d_model, act_type):\n",
    "        super().__init__()\n",
    "        self.W_in = nn.Parameter(torch.randn(d_model, d_model)/np.sqrt(d_model))\n",
    "        self.b_in = nn.Parameter(torch.zeros(d_model))\n",
    "        self.act_type = act_type\n",
    "        self.hook_pre = HookPoint()\n",
    "        self.hook_post = HookPoint()\n",
    "        assert act_type in ['ReLU', 'GeLU', 'Tanh']\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.einsum('md,bpd->bpm', self.W_in, self.hook_pre(x)) + self.b_in\n",
    "        if self.act_type=='ReLU':\n",
    "            x = F.relu(x)\n",
    "        elif self.act_type=='GeLU':\n",
    "            x = F.gelu(x)\n",
    "        elif self.act_type=='Tanh':\n",
    "            x = F.tanh(x)\n",
    "        x = self.hook_post(x)\n",
    "        return x\n",
    "        \n",
    "# Transformer Block\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, d_head, num_heads, n_ctx, act_type, attn_coeff):\n",
    "        super().__init__()\n",
    "        self.attn = Attention(d_model, num_heads, d_head, n_ctx, attn_coeff=attn_coeff)\n",
    "        self.mlp = MLP(d_model, d_model*4,act_type)\n",
    "        self.hook_attn_out = HookPoint()\n",
    "        self.hook_mlp_out = HookPoint()\n",
    "        self.hook_resid_pre = HookPoint()\n",
    "        self.hook_resid_mid = HookPoint()\n",
    "        self.hook_resid_post = HookPoint()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.hook_resid_mid(x + self.hook_attn_out(self.attn(self.hook_resid_pre(x))))\n",
    "        x = self.hook_resid_post(x + self.hook_mlp_out(self.mlp(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "# -\n",
    "\n",
    "# Full transformer\n",
    "class Transformer(nn.Module): # Model B\n",
    "    def __init__(self, num_layers, d_vocab, d_model, d_head, num_heads, n_ctx, act_type, attn_coeff, use_cache=False, use_ln=True):\n",
    "        super().__init__()\n",
    "        assert 0<=attn_coeff<=1\n",
    "        print('parameters', num_layers, d_vocab, d_model, d_head, num_heads, n_ctx, act_type, attn_coeff, use_cache, use_ln)\n",
    "        self.cache = {}\n",
    "        self.use_cache = use_cache\n",
    "\n",
    "        self.embed = Embed(d_vocab, d_model)\n",
    "        self.pos_embed = PosEmbed(n_ctx, d_model)\n",
    "        self.unembed = Unembed(d_vocab, d_model)\n",
    "        self.use_ln = use_ln\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(d_model, d_head, num_heads, n_ctx, act_type, attn_coeff) for i in range(num_layers)])\n",
    "\n",
    "        for name, module in self.named_modules():\n",
    "            if type(module)==HookPoint:\n",
    "                module.give_name(name)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.pos_embed(x)\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        x = self.unembed(x)\n",
    "        return x\n",
    "\n",
    "    def set_use_cache(self, use_cache):\n",
    "        self.use_cache = use_cache\n",
    "    \n",
    "    def hook_points(self):\n",
    "        return [module for name, module in self.named_modules() if 'hook' in name]\n",
    "\n",
    "    def remove_all_hooks(self):\n",
    "        for hp in self.hook_points():\n",
    "            hp.remove_hooks('fwd')\n",
    "            hp.remove_hooks('bwd')\n",
    "    \n",
    "    def cache_all(self, cache, incl_bwd=False):\n",
    "        # Caches all activations wrapped in a HookPoint\n",
    "        def save_hook(tensor, name):\n",
    "            cache[name] = tensor.detach()\n",
    "        def save_hook_back(tensor, name):\n",
    "            cache[name+'_grad'] = tensor[0].detach()\n",
    "        for hp in self.hook_points():\n",
    "            hp.add_hook(save_hook, 'fwd')\n",
    "            if incl_bwd:\n",
    "                hp.add_hook(save_hook_back, 'bwd')\n",
    "    \n",
    "    def parameters_norm(self):\n",
    "        # Returns the l2 norm of all parameters\n",
    "        return sum([torch.sum(p*p).item() for p in self.parameters()])**0.5\n",
    "    \n",
    "    def l2_norm(self):\n",
    "        # Returns the l2 norm of all parameters\n",
    "        return sum([torch.sum(p*p) for p in self.parameters()])\n",
    "    \n",
    "    def parameters_flattened(self):\n",
    "        # Returns all parameters as a single tensor\n",
    "        return torch.cat([p.view(-1) for p in self.parameters()]).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "class Linearformer(nn.Module): # Model A???\n",
    "    def __init__(self, num_layers, d_vocab, d_model, d_head, num_heads, n_ctx, act_type, attn_coeff, use_cache=False, use_ln=True):\n",
    "        super().__init__()\n",
    "        print('parameters(L)', num_layers, d_vocab, d_model, d_head, num_heads, n_ctx, act_type, attn_coeff, use_cache, use_ln)\n",
    "        self.cache = {}\n",
    "        self.use_cache = use_cache\n",
    "        self.attn_coeff = attn_coeff\n",
    "\n",
    "        self.embed = Embed(d_vocab, d_model//n_ctx)\n",
    "        # pos embed is being commented in original code\n",
    "        self.pos_embed = PosEmbed(n_ctx, d_model)\n",
    "        self.unembed = Unembed(d_vocab, d_model)\n",
    "        self.use_ln = use_ln\n",
    "        self.blocks = nn.ModuleList([MyLinear(d_model, act_type) for i in range(num_layers)])\n",
    "        self.padder = nn.ConstantPad1d((0,d_model%n_ctx),0)\n",
    "\n",
    "        for name, module in self.named_modules():\n",
    "            if type(module)==HookPoint:\n",
    "                module.give_name(name)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        #print(x.shape)\n",
    "        x = x.reshape(-1,1,x.shape[1]*x.shape[2])\n",
    "        #print(x.shape)\n",
    "        x = self.padder(x)\n",
    "        #print(x.shape)\n",
    "        #print(x.shape)\n",
    "        assert len(x.shape)==3 and x.shape[1:]==(1,d_model)\n",
    "        x = self.pos_embed(x)\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        x = self.unembed(x)\n",
    "        return x\n",
    "\n",
    "    def set_use_cache(self, use_cache):\n",
    "        self.use_cache = use_cache\n",
    "    \n",
    "    def hook_points(self):\n",
    "        return [module for name, module in self.named_modules() if 'hook' in name]\n",
    "\n",
    "    def remove_all_hooks(self):\n",
    "        for hp in self.hook_points():\n",
    "            hp.remove_hooks('fwd')\n",
    "            hp.remove_hooks('bwd')\n",
    "    \n",
    "    def cache_all(self, cache, incl_bwd=False):\n",
    "        # Caches all activations wrapped in a HookPoint\n",
    "        def save_hook(tensor, name):\n",
    "            cache[name] = tensor.detach()\n",
    "        def save_hook_back(tensor, name):\n",
    "            cache[name+'_grad'] = tensor[0].detach()\n",
    "        for hp in self.hook_points():\n",
    "            hp.add_hook(save_hook, 'fwd')\n",
    "            if incl_bwd:\n",
    "                hp.add_hook(save_hook_back, 'bwd')\n",
    "    \n",
    "    def parameters_norm(self):\n",
    "        # Returns the l2 norm of all parameters\n",
    "        return sum([torch.sum(p*p).item() for p in self.parameters()])**0.5\n",
    "    \n",
    "    def l2_norm(self):\n",
    "        # Returns the l2 norm of all parameters\n",
    "        return sum([torch.sum(p*p) for p in self.parameters()])\n",
    "    \n",
    "    def parameters_flattened(self):\n",
    "        # Returns all parameters as a single tensor\n",
    "        return torch.cat([p.view(-1) for p in self.parameters()]).detach().cpu().numpy()\n",
    "\n",
    "DEVICE='cuda'\n",
    "# DEVICE='cuda:'+str(random.randint(0,1))\n",
    "print(DEVICE)\n",
    "class MyAddDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, func, C, diff_vocab=False, eqn_sign=False):\n",
    "        self.func = func\n",
    "        dim = 2\n",
    "        self.dim = dim\n",
    "        self.C = C\n",
    "        self.inputs = []\n",
    "        self.outputs = []\n",
    "        self.vocab=C\n",
    "        if diff_vocab:\n",
    "            self.vocab*=2\n",
    "        if eqn_sign:\n",
    "            self.vocab+=1\n",
    "            self.dim+=1\n",
    "        self.vocab_out=0\n",
    "        for p in range(C**dim):\n",
    "            x = np.unravel_index(p, (C,)*dim)\n",
    "            o=self.func(x)\n",
    "            s=[x[0],x[1]]\n",
    "            if diff_vocab:\n",
    "                s[1]+=C\n",
    "            if eqn_sign:\n",
    "                s.append(self.vocab-1)\n",
    "            self.inputs.append(s)\n",
    "            self.outputs.append(o)\n",
    "            self.vocab_out=max(self.vocab_out, o+1)\n",
    "        if self.vocab_out!=C:\n",
    "            print(f'warning {self.vocab_out=} neq to {C=}')\n",
    "        self.inputs = torch.tensor(self.inputs, dtype=torch.long, device=DEVICE)\n",
    "        self.outputs = torch.tensor(self.outputs, dtype=torch.long, device=DEVICE)\n",
    "        # print(self.inputs,self.outputs)\n",
    "    def __len__(self):\n",
    "        return len(self.outputs)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.outputs[idx]\n",
    "\n",
    "def cross_entropy_high_precision(logits, labels):\n",
    "    # Shapes: batch x vocab, batch\n",
    "    # Cast logits to float64 because log_softmax has a float32 underflow on overly \n",
    "    # confident data and can only return multiples of 1.2e-7 (the smallest float x\n",
    "    # such that 1+x is different from 1 in float32). This leads to loss spikes \n",
    "    # and dodgy gradients\n",
    "    logprobs = F.log_softmax(logits.to(torch.float64), dim=-1)\n",
    "    prediction_logprobs = torch.gather(logprobs, index=labels[:, None], dim=-1)\n",
    "    loss = -torch.mean(prediction_logprobs)\n",
    "    return loss\n",
    "\n",
    "def run_experiment(config):\n",
    "    exp_name=config['name']\n",
    "    print('parsing func',config['funcs'])\n",
    "    config['func']=eval(config['funcs'])\n",
    "    #useLinear=config.get('use_linear',False)\n",
    "    full_dataset = MyAddDataSet(func=config['func'],C=config['C'],diff_vocab=config['diff_vocab'],eqn_sign=config['eqn_sign'])\n",
    "    model = Transformer(\n",
    "        num_layers=config.get('n_layers',1),\n",
    "        num_heads=config['n_heads'],\n",
    "        d_model=config['d_model'],\n",
    "        d_head=config.get('d_head',config['d_model']//config['n_heads']),\n",
    "        attn_coeff=config['attn_coeff'],\n",
    "        d_vocab=full_dataset.vocab,\n",
    "#        attention_dir=config.get('attention_dir','bidirectional'),\n",
    "        act_type=config.get('act_fn','relu'),\n",
    "        n_ctx=full_dataset.dim,\n",
    "#        normalization_type=None,\n",
    "    )\n",
    "    model.to(DEVICE)\n",
    "    train_frac = config['trainfrac']\n",
    "    train_size = int(config['frac'] * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "    if train_frac is not None:\n",
    "        new_train_size = int(train_frac * train_size)\n",
    "        remove_size = train_size - new_train_size\n",
    "        train_dataset, _ = torch.utils.data.random_split(train_dataset, [new_train_size, remove_size])\n",
    "    print('random split',len(train_dataset),len(test_dataset))\n",
    "    batch_size = config.get('batch_size',len(full_dataset))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    opt = optim.AdamW(model.parameters(),lr=config.get('lr',1e-3),weight_decay=config.get('weight_decay',1e-4),betas=(0.9,0.98))\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(opt, lambda step: min(step/10, 1)) # 10 epoch warmup\n",
    "    print(config.get('lr',1e-3),config.get('weight_decay',1e-4))\n",
    "    print(opt,scheduler)\n",
    "    losses=[]\n",
    "    accs=[]\n",
    "    losses_val=[]\n",
    "    accs_val=[]\n",
    "    norms=[]\n",
    "    loss_val=10\n",
    "    acc_val=0\n",
    "    stop=None\n",
    "    best_train_acc=0.\n",
    "    best_test_acc=0.\n",
    "    perfect_train_time=None\n",
    "    perfect_test_time=None\n",
    "\n",
    "    # modification start here\n",
    "    embeddings=[]\n",
    "    pbar = tqdm.tqdm(range(config.get('epoch',10000)))\n",
    "    gaps=[]\n",
    "    early_stop_a=2\n",
    "    early_stop_b=1\n",
    "    if config.get('early_stop',None) is not None:\n",
    "        early_stop_a, early_stop_b = config['early_stop']\n",
    "    early_stop_timer=0\n",
    "    #model.train()\n",
    "\n",
    "    run = wandb.init(reinit=True,config=config,project='modadd_longer')#,settings=wandb.Settings(start_method=\"spawn\"))\n",
    "    try:\n",
    "        for i in pbar:\n",
    "            def evaluation():\n",
    "                nonlocal best_test_acc\n",
    "                nonlocal perfect_test_time\n",
    "                nonlocal early_stop_timer\n",
    "                nonlocal early_stop_a\n",
    "                nonlocal early_stop_b\n",
    "                # evaluate on test set, return loss and accuracy\n",
    "                # with torch.inference_mode():\n",
    "                    #model.eval()\n",
    "                losses_eval=[]\n",
    "                accs_eval=[]\n",
    "                for inp,ans in test_loader:\n",
    "                    # print(inp.shape)\n",
    "                    out = model(inp)[:,-1,:]\n",
    "                    loss = cross_entropy_high_precision(out,ans)\n",
    "                    acc = torch.sum((out.argmax(dim=1)==ans).float())/len(ans)\n",
    "                    # print(inp,'test',out.argmax(dim=1),ans)\n",
    "#                    acc = (out.argmax(dim=1)==ans).float().mean()\n",
    "                    losses_eval.append(loss.item())\n",
    "                    accs_eval.append(acc.item())\n",
    "                    # print(loss,acc)\n",
    "                #print(losses_eval,accs_eval)\n",
    "                eval_loss, eval_acc = np.mean(losses_eval), np.mean(accs_eval)\n",
    "                best_test_acc = max(best_test_acc, eval_acc)\n",
    "                if eval_acc==1. and perfect_test_time is None:\n",
    "                    perfect_test_time = i\n",
    "                if eval_acc>=early_stop_a:\n",
    "                    early_stop_timer+=1\n",
    "                else:\n",
    "                    early_stop_timer=0\n",
    "                #print(eval_loss,eval_acc)\n",
    "                return eval_loss, eval_acc\n",
    "            if early_stop_timer>=early_stop_b:\n",
    "                break\n",
    "            for inp,ans in train_loader:\n",
    "                #print(inp.shape,inp.dtype)\n",
    "                # print(inp,'train')\n",
    "                #print(len(inp))\n",
    "                #model.train()\n",
    "                out = model(inp)[:,-1,:]\n",
    "                loss = cross_entropy_high_precision(out,ans)\n",
    "                loss_val, acc_val = evaluation()\n",
    "                #print(loss_val,acc_val)\n",
    "                loss.backward()\n",
    "                # clip gradients\n",
    "                #if config.get('clip',None) is not None:\n",
    "                #    nn.utils.clip_grad_norm_(model.parameters(), config['clip'])\n",
    "                opt.step()\n",
    "                scheduler.step()\n",
    "                opt.zero_grad()\n",
    "                acc = (out.argmax(dim=1)==ans).float().mean()\n",
    "                norm = sum([torch.sum(p*p).item() for p in model.parameters()])**0.5\n",
    "                #sum(p.norm()**2 for p in model.parameters()).sqrt().item()\n",
    "\n",
    "                # save every 10 epochs\n",
    "                if config['save_embeddings'] and i % 10 == 9:\n",
    "                    embeddings.append(extract_embeddings(model))\n",
    "                \n",
    "                losses.append(loss.item())\n",
    "                accs.append(acc.item())\n",
    "                losses_val.append(loss_val)\n",
    "                accs_val.append(acc_val)\n",
    "                norms.append(norm)\n",
    "\n",
    "                best_train_acc=max(best_train_acc,acc.item())\n",
    "                if acc.item()==1. and perfect_train_time is None:\n",
    "                    perfect_train_time = i\n",
    "                gaps.append(best_train_acc-best_test_acc)\n",
    "                pbar.set_description(f\"loss: {loss.item():.3f}, accm: {best_train_acc:.3f}, vloss: {loss_val:.3f}, vaccm: {best_test_acc:.3f}, norm: {norm:.3f}, acc: {acc.item():.3f}, vacc: {acc_val:.3f}\")\n",
    "                #print(f\"loss: {loss.item():.3f}, accm: {best_train_acc:.3f}, vloss: {loss_val:.3f}, vaccm: {best_test_acc:.3f}, norm: {norm:.3f}, acc: {acc.item():.3f}, vacc: {acc_val:.3f}\")\n",
    "                run.log({'training_loss': loss.item(),\n",
    "                'validation_loss': loss_val,\n",
    "                'training_accuracy': acc.item(),\n",
    "                'validation_accuracy': acc_val,\n",
    "                'parameter_norm': norm,\n",
    "                'best_train_accuracy': best_train_acc,\n",
    "                'best_test_accuracy': best_test_acc,\n",
    "                'generalization_gap': best_train_acc-best_test_acc,\n",
    "                'generalization_delay1': sum(gaps)})\n",
    "    except KeyboardInterrupt:\n",
    "        print('Keyboard interrupt. Gracefully exiting...')\n",
    "        pass\n",
    "    print('Finished.')\n",
    "    generalization_gap=best_train_acc-best_test_acc\n",
    "    generalization_delay1=sum(gaps)\n",
    "    generalization_delay2=sum(max(t-(best_train_acc-best_test_acc),0) for t in gaps)\n",
    "    run.summary[\"generalization_delay2\"] = generalization_delay2\n",
    "    # run.finish()\n",
    "    return dict(\n",
    "        losses=losses,\n",
    "        accs=accs,\n",
    "        losses_val=losses_val,\n",
    "        accs_val=accs_val,\n",
    "        norms=norms,\n",
    "        model=model,\n",
    "        config=config,\n",
    "        generalization_gap=generalization_gap,\n",
    "        generalization_delay1=generalization_delay1,\n",
    "        generalization_delay2=generalization_delay2,\n",
    "        best_train_acc=best_train_acc,\n",
    "        best_test_acc=best_test_acc,\n",
    "        perfect_train_time=perfect_train_time,\n",
    "        perfect_test_time=perfect_test_time,\n",
    "        dataset=full_dataset,\n",
    "        embeddings=embeddings,\n",
    "        run=run\n",
    "    )\n",
    "\n",
    "import random\n",
    "import string\n",
    "import seaborn as sns\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9689c6",
   "metadata": {
    "papermill": {
     "duration": 0.002675,
     "end_time": "2024-12-08T02:42:11.270275",
     "exception": false,
     "start_time": "2024-12-08T02:42:11.267600",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Just change size of C (attention rate [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48e5c07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T02:42:11.277121Z",
     "iopub.status.busy": "2024-12-08T02:42:11.276715Z",
     "iopub.status.idle": "2024-12-08T02:42:11.282761Z",
     "shell.execute_reply": "2024-12-08T02:42:11.282035Z"
    },
    "papermill": {
     "duration": 0.011377,
     "end_time": "2024-12-08T02:42:11.284270",
     "exception": false,
     "start_time": "2024-12-08T02:42:11.272893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# C_list = [19,29,39,49,59,89,119,239]\n",
    "# for attention_rate in [0, 1]:\n",
    "#     for c in C_list:\n",
    "#         experiment_name = 'C'\n",
    "#         modify_part = f'C{c}'\n",
    "#         # for use_linear in [False]: # false model B, true model A\n",
    "#         # letters_and_numbers = string.ascii_lowercase + string.digits.replace('0', '')\n",
    "#         #run_name = 'A_repr_'.join(random.choices(letters_and_numbers, k=10))\n",
    "#         # run_name = 'A_repr_trans_'+str(count+1)\n",
    "    \n",
    "#         # attn_coeff=random.uniform(0,1)\n",
    "#         attn_coeff = attention_rate\n",
    "#         epoch = 20000 #è·‘çš„æ—¶é—´å®žåœ¨å¤ªä¹…\n",
    "#         if attn_coeff == 0:\n",
    "#             run_name = f\"A_{modify_part}\"\n",
    "#         else:\n",
    "#             run_name = f\"B_{modify_part}\"\n",
    "#         print(run_name)\n",
    "#         C=c\n",
    "#         n_layers=1\n",
    "#         # if random.randint(0,3):\n",
    "#         #     n_layers=random.randint(1,4)\n",
    "#         # frac_coeff=0.8\n",
    "#         diff_vocab=0\n",
    "#         eqn_sign=0\n",
    "#         # if random.randint(0,4)==0:\n",
    "#         #     diff_vocab=random.randint(0,1)\n",
    "#         #     eqn_sign=random.randint(0,1)\n",
    "#         d_model=128\n",
    "#         # if random.randint(0,2)==0:\n",
    "#         #     d_model=int(2**random.uniform(5,9))\n",
    "#         print(f'd={d_model}')\n",
    "#         config=dict(\n",
    "#             name='modadd_'+str(C),\n",
    "#             funcs='lambda x: (x[0]+x[1])%'+str(C),\n",
    "#             C=C,\n",
    "#             n_heads=4,\n",
    "#             d_model=d_model,\n",
    "#             n_layers=n_layers,\n",
    "#             attention_dir='casual',\n",
    "#             # act_fn='GeLU' if random.randint(0,3)==0 else 'ReLU',\n",
    "#             act_fn='ReLU',\n",
    "#             epoch=epoch,\n",
    "#             batch_size=C*C,\n",
    "#             lr=1e-3,\n",
    "#             weight_decay=2.,\n",
    "#             frac=0.8,\n",
    "#             trainfrac=None,\n",
    "#             # should adjust the attn_coeff\n",
    "#             # attn_coeff=frac_coeff,\n",
    "#             attn_coeff=attn_coeff,\n",
    "#             runid=run_name,\n",
    "#             diff_vocab=diff_vocab,\n",
    "#             eqn_sign=eqn_sign,\n",
    "#             # use_linear=use_linear,\n",
    "#             save_embeddings=False,\n",
    "#         )\n",
    "#         result_modadd=run_experiment(config)\n",
    "    \n",
    "#         # save embeddings, see analysis.utils.extract_embeddings for details\n",
    "#         if config['save_embeddings']:\n",
    "#             embed_path = f'result/model_{\"B\" if config[\"attn_coeff\"] else \"A\"}_embeddings.npz'\n",
    "#             np.savez_compressed(os.path.join(root_path, embed_path), result_modadd['embeddings'])\n",
    "    \n",
    "#         # dataset = result_modadd['dataset']\n",
    "#         # dataloader = torch.utils.data.DataLoader(dataset, batch_size=C*C)\n",
    "#         # model = result_modadd['model']\n",
    "#         # oo=[[0]*C for _ in range(C)]\n",
    "#         # oc=[[0]*C for _ in range(C)]\n",
    "#         # for x,y in dataloader:\n",
    "#         #     with torch.inference_mode():\n",
    "#         #         model.eval()\n",
    "#         #         o=model(x)[:,-1,:]\n",
    "#         #         o0=o[list(range(len(x))),y]\n",
    "#         #         o0=o0.cpu()\n",
    "#         #         x=x.cpu()\n",
    "#         #         for p,q in zip(o0,x):\n",
    "#         #             A,B=int(q[0].item()),int(q[1].item())\n",
    "#         #             oo[(A+B)%C][(A-B)%C]=p.item()\n",
    "#         #         o[list(range(len(x))),y]=float(\"-inf\")\n",
    "#         #         o1=o.topk(dim=-1,k=2).values.cpu()\n",
    "#         #         print(o1)\n",
    "#         #         for p,q in zip(o1,x):\n",
    "#         #             A,B=int(q[0].item()),int(q[1].item())\n",
    "#         #             oc[(A+B)%C][(A-B)%C]=p[0].item()\n",
    "#         # use seaborn to plot the heatmap of oo\n",
    "        \n",
    "#         run=result_modadd['run']\n",
    "#         # oo=np.array(oc)\n",
    "#         # dd=np.mean(np.std(oo,axis=0))/np.std(oo.flatten())\n",
    "#         # #print('dd',dd)\n",
    "#         # run.summary['distance_irrelevancy']=dd\n",
    "#         # run.summary['logits']=oo\n",
    "#         # mi,mx=np.min(oo),np.max(oo)\n",
    "#         # oo=(oo-mi)/(mx-mi)\n",
    "#         # run.summary['logits_normalized']=oo\n",
    "#         # sns.heatmap(np.array(oo))\n",
    "#         # sb=[]\n",
    "#         # sx=[]\n",
    "#         # sc=[]\n",
    "#         # ss=[]\n",
    "#         # for i in range(C):\n",
    "#         #     s=oo[:,i]\n",
    "#         #     sb.append(np.median(s))\n",
    "#         #     ss.append(np.mean(s))\n",
    "#         #     sx.append(np.std(oo[i]))\n",
    "#         # print('std(med(col))',np.std(sb))\n",
    "#         # print('mean(std(row))',np.mean(sx))\n",
    "#         # run.summary['std_med_col']=np.std(sb)\n",
    "#         # run.summary['mean_std_row']=np.mean(sx)\n",
    "#         # run.summary['std_mean_col']=np.std(ss)\n",
    "#         # run.summary['med_std_row']=np.median(sx)\n",
    "#         path = root_path + f'/save/{experiment_name}'\n",
    "#         if not os.path.exists(path):\n",
    "#             os.makedirs(path)\n",
    "#         model_name=os.path.join(root_path, f'{path}/model_{run_name}.pt')\n",
    "#         model=result_modadd['model']\n",
    "#         torch.save(model.state_dict(), model_name)\n",
    "#         import json\n",
    "#         config['func']=None\n",
    "#         with open(os.path.join(root_path, f'{path}/config_{run_name}.json'),'w') as f:\n",
    "#             json.dump(config,f,separators=(',\\n', ': '))\n",
    "#         run.finish()\n",
    "    \n",
    "#     # !python -m wandb offline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2158440f",
   "metadata": {
    "papermill": {
     "duration": 0.002422,
     "end_time": "2024-12-08T02:42:11.289517",
     "exception": false,
     "start_time": "2024-12-08T02:42:11.287095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### keep C = 59 but change the frac of training set, attention rate [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e7c00b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T02:42:11.295824Z",
     "iopub.status.busy": "2024-12-08T02:42:11.295556Z",
     "iopub.status.idle": "2024-12-08T06:17:22.024047Z",
     "shell.execute_reply": "2024-12-08T06:17:22.023184Z"
    },
    "papermill": {
     "duration": 12910.733643,
     "end_time": "2024-12-08T06:17:22.025706",
     "exception": false,
     "start_time": "2024-12-08T02:42:11.292063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.1\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 278 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f57544b50c0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myhanmowsnoo\u001b[0m (\u001b[33myhanmowsnoo-royal-institute-of-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_024212-m1v5cmoz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrobust-salad-201\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/m1v5cmoz\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 46.002, vaccm: 0.080, norm: 22.077, acc: 1.000, vacc: 0.080: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [05:35<00:00, 59.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–â–‚â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 0.08034\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 18372.89798\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 2.39782\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0.91966\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 22.07692\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 0.08034\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 46.0016\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mrobust-salad-201\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/m1v5cmoz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_024212-m1v5cmoz/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.2\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 556 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f56683b28f0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_024749-nymmnt0d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdesert-deluge-203\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/nymmnt0d\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 30.761, vaccm: 0.162, norm: 26.776, acc: 1.000, vacc: 0.161: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [06:27<00:00, 51.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–ˆâ–ˆâ–ˆâ–†â–…â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 0.16212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 16747.49926\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 19.42573\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0.83788\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 26.77645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 0.16069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 30.76119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mdesert-deluge-203\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/nymmnt0d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_024749-nymmnt0d/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.3\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 835 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f5669551d80>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_025419-fv61tngl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfaithful-resonance-206\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/fv61tngl\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 0.261, vaccm: 0.948, norm: 23.913, acc: 1.000, vacc: 0.931: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [07:52<00:00, 42.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–ƒâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–…â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–…â–…â–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–â–â–â–â–â–â–â–‚â–‚â–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–†â–…â–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 0.94835\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 4497.42539\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 3464.82417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0.05165\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.91301\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 0.93113\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.26064\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mfaithful-resonance-206\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/fv61tngl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_025419-fv61tngl/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.4\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1113 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f56694b4430>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_030213-izmyx8hh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdark-energy-208\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/izmyx8hh\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.448, acc: 1.000, vacc: 1.000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [08:33<00:00, 38.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–ƒâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–ˆâ–ˆâ–‡â–…â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–ƒâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 526.61283\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 526.64222\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.44775\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 3e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mdark-energy-208\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/izmyx8hh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_030213-izmyx8hh/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.5\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1392 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f56683b3550>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_031048-sklgppk8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33molive-sun-210\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/sklgppk8\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 22.590, acc: 1.000, vacc: 1.000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [09:38<00:00, 34.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–…â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–ˆâ–†â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–ˆâ–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–‚â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–ˆâ–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 384.85098\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 384.86302\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 22.59\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33molive-sun-210\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/sklgppk8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_031048-sklgppk8/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.6\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1670 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f564c149750>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_032028-fs4ug2y7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdutiful-music-213\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/fs4ug2y7\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 0.002, vaccm: 1.000, norm: 24.459, acc: 1.000, vacc: 1.000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [11:04<00:00, 30.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–ƒâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–ˆâ–‡â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–†â–ˆâ–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–ˆâ–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 269.8441\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 269.8441\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 24.45864\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.00217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mdutiful-music-213\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/fs4ug2y7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_032028-fs4ug2y7/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.7\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1948 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f56683b0310>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_033134-gz3stp17\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlively-field-215\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/gz3stp17\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 22.961, acc: 1.000, vacc: 1.000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [12:18<00:00, 27.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–ƒâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 136.76729\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 136.76729\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 22.96112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mlively-field-215\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/gz3stp17\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_033134-gz3stp17/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.8\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 2227 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f564c1484f0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_034354-7vhwmmtb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmagic-bush-218\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/7vhwmmtb\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.777, acc: 1.000, vacc: 1.000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [15:16<00:00, 21.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 65.58514\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 65.58514\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.77735\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mmagic-bush-218\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/7vhwmmtb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_034354-7vhwmmtb/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.9\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 2505 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f562dfd5c60>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_035911-std4e7nq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpeachy-donkey-220\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/std4e7nq\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 22.734, acc: 1.000, vacc: 1.000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [14:49<00:00, 22.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–ˆâ–‡â–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 74.25344\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 74.25463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap -0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 22.73404\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mpeachy-donkey-220\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/std4e7nq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_035911-std4e7nq/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac1.0\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 2784 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f56694b4cd0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_041402-74xiizdl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33melated-capybara-223\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/74xiizdl\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.016, acc: 1.000, vacc: 1.000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [16:32<00:00, 20.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–ˆâ–„â–ƒâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 43.8101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 43.85577\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.01596\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33melated-capybara-223\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/74xiizdl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_041402-74xiizdl/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_frac0.1\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 1 False True\n",
      "random split 278 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f5669551450>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_043036-mmbyld8x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtreasured-fire-226\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/mmbyld8x\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 53.909, vaccm: 0.019, norm: 22.336, acc: 1.000, vacc: 0.007: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [05:40<00:00, 58.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–ˆâ–†â–…â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–â–â–â–â–â–â–â–â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–…â–…â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–„â–„â–„â–„â–„â–…â–…â–‚â–„â–„â–„â–„â–„â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–â–„â–†â–†â–‡â–‡â–‡â–…â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 0.01865\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 19595.60944\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0.98135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 22.33637\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 0.00717\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 53.90903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mtreasured-fire-226\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/mmbyld8x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_043036-mmbyld8x/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_frac0.2\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 1 False True\n",
      "random split 556 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f56694fd3f0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_043618-r7vrvudy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfresh-moon-227\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/r7vrvudy\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 36.384, vaccm: 0.016, norm: 33.080, acc: 1.000, vacc: 0.004: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [06:30<00:00, 51.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–ˆâ–…â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–„â–„â–„â–‚â–‚â–â–‚â–‚â–„â–‚â–â–â–â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–‚â–â–â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–„â–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–„â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–„â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–„â–…â–‡â–ˆâ–ƒâ–„â–…â–†â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 0.01578\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 19639.19784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0.98422\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 33.07999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 36.38409\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mfresh-moon-227\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/r7vrvudy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_043618-r7vrvudy/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_frac0.3\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 1 False True\n",
      "random split 835 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f57544b5300>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_044250-zsaaevtw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mscarlet-water-229\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/zsaaevtw\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 23.464, vaccm: 0.043, norm: 30.937, acc: 1.000, vacc: 0.042: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [07:30<00:00, 44.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–†â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–ˆâ–‡â–‡â–‡â–‡â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–…â–…â–†â–…â–…â–…â–…â–…â–„â–„â–…â–…â–„â–„â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–„â–„â–„â–†â–…â–…â–…â–…â–…â–„â–„â–„â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 0.04304\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 19385.85499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 297.51087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0.95696\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 30.93677\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 0.04161\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 23.4637\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mscarlet-water-229\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/zsaaevtw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_044250-zsaaevtw/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_frac0.4\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 1 False True\n",
      "random split 1113 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f56683b8250>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_045022-ibxo8ru6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mclassic-surf-230\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/ibxo8ru6\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 25.706, acc: 1.000, vacc: 1.000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [08:20<00:00, 39.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–…â–ˆâ–ˆâ–‡â–…â–…â–…â–„â–„â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 4160.00012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 4160.03223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 25.70597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mclassic-surf-230\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/ibxo8ru6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_045022-ibxo8ru6/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_frac0.5\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 1 False True\n",
      "random split 1392 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f56683b8eb0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_045843-1qrm3hev\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mkind-resonance-232\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/1qrm3hev\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 26.265, acc: 1.000, vacc: 1.000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [09:23<00:00, 35.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–‚â–ƒâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–â–ƒâ–„â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–ˆâ–‡â–‡â–†â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–â–â–‚â–‚â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–„â–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 812.72023\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 812.72592\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 26.26499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mkind-resonance-232\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/1qrm3hev\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_045843-1qrm3hev/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_frac0.6\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 1 False True\n",
      "random split 1670 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f562e547760>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_050808-emwmhsr8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcurious-tree-234\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/emwmhsr8\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 26.301, acc: 1.000, vacc: 1.000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [11:13<00:00, 29.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–‚â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–ˆâ–†â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–ˆâ–‡â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 314.41318\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 314.43108\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 26.3013\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mcurious-tree-234\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/emwmhsr8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_050808-emwmhsr8/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_frac0.7\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 1 False True\n",
      "random split 1948 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f5669550ac0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_051923-k2xhwsng\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvital-dawn-235\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/k2xhwsng\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 25.091, acc: 1.000, vacc: 1.000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [11:59<00:00, 27.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–„â–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–ˆâ–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–ˆâ–‡â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–ˆâ–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 346.63721\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 346.64857\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 25.09115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mvital-dawn-235\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/k2xhwsng\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_051923-k2xhwsng/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_frac0.8\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 1 False True\n",
      "random split 2227 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f56694cf190>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_053125-c55ft6n0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtough-butterfly-238\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/c55ft6n0\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 24.203, acc: 1.000, vacc: 1.000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [14:56<00:00, 22.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–†â–‡â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 104.98308\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 104.98518\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 24.20335\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mtough-butterfly-238\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/c55ft6n0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_053125-c55ft6n0/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_frac0.9\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 1 False True\n",
      "random split 2505 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f566952cbb0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_054623-3o2yfyat\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgood-water-240\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/3o2yfyat\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 24.028, acc: 1.000, vacc: 1.000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [14:41<00:00, 22.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 76.68084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 76.68248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap -0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 24.02801\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mgood-water-240\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/3o2yfyat\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_054623-3o2yfyat/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_frac1.0\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 1 False True\n",
      "random split 2784 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7f564c14bc70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241208_060106-kqlrrrvr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbreezy-leaf-243\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/kqlrrrvr\u001b[0m\n",
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 24.460, acc: 1.000, vacc: 1.000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [16:13<00:00, 20.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 â–â–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm â–ˆâ–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss â–ˆâ–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss â–ˆâ–…â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 49.20323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 49.27067\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 24.46009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mbreezy-leaf-243\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/kqlrrrvr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241208_060106-kqlrrrvr/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for attention_rate in [0, 1]:\n",
    "    for trainfrac in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n",
    "        experiment_name = 'trainfrac'\n",
    "        modify_part = f'frac{trainfrac}'\n",
    "        # for use_linear in [False]: # false model B, true model A\n",
    "        # letters_and_numbers = string.ascii_lowercase + string.digits.replace('0', '')\n",
    "        #run_name = 'A_repr_'.join(random.choices(letters_and_numbers, k=10))\n",
    "        # run_name = 'A_repr_trans_'+str(count+1)\n",
    "        attn_coeff = attention_rate\n",
    "        epoch = 20000 #è·‘çš„æ—¶é—´å®žåœ¨å¤ªä¹…\n",
    "        if attn_coeff == 0:\n",
    "            run_name = f\"A_{modify_part}\"\n",
    "        else:\n",
    "            run_name = f\"B_{modify_part}\"\n",
    "        print(run_name)\n",
    "        C=59\n",
    "        n_layers=1\n",
    "        # if random.randint(0,3):\n",
    "        #     n_layers=random.randint(1,4)\n",
    "        # frac_coeff=0.8\n",
    "        diff_vocab=0\n",
    "        eqn_sign=0\n",
    "        # if random.randint(0,4)==0:\n",
    "        #     diff_vocab=random.randint(0,1)\n",
    "        #     eqn_sign=random.randint(0,1)\n",
    "        d_model=128\n",
    "        # if random.randint(0,2)==0:\n",
    "        #     d_model=int(2**random.uniform(5,9))\n",
    "        print(f'd={d_model}')\n",
    "        config=dict(\n",
    "            name='modadd_59',\n",
    "            funcs='lambda x: (x[0]+x[1])%59',\n",
    "            C=C,\n",
    "            n_heads=4,\n",
    "            d_model=d_model,\n",
    "            n_layers=n_layers,\n",
    "            attention_dir='casual',\n",
    "            # act_fn='GeLU' if random.randint(0,3)==0 else 'ReLU',\n",
    "            act_fn='ReLU',\n",
    "            epoch=epoch,\n",
    "            batch_size=C*C,\n",
    "            lr=1e-3,\n",
    "            weight_decay=2.,\n",
    "            frac=0.8,\n",
    "            trainfrac=trainfrac,\n",
    "            # should adjust the attn_coeff\n",
    "            # attn_coeff=frac_coeff,\n",
    "            attn_coeff=attn_coeff,\n",
    "            runid=run_name,\n",
    "            diff_vocab=diff_vocab,\n",
    "            eqn_sign=eqn_sign,\n",
    "            # use_linear=use_linear,\n",
    "            save_embeddings=False,\n",
    "        )\n",
    "        result_modadd=run_experiment(config)\n",
    "    \n",
    "        # save embeddings, see analysis.utils.extract_embeddings for details\n",
    "        if config['save_embeddings']:\n",
    "            embed_path = f'result/model_{\"B\" if config[\"attn_coeff\"] else \"A\"}_embeddings.npz'\n",
    "            np.savez_compressed(os.path.join(root_path, embed_path), result_modadd['embeddings'])\n",
    "    \n",
    "        # dataset = result_modadd['dataset']\n",
    "        # dataloader = torch.utils.data.DataLoader(dataset, batch_size=C*C)\n",
    "        # model = result_modadd['model']\n",
    "        # oo=[[0]*C for _ in range(C)]\n",
    "        # oc=[[0]*C for _ in range(C)]\n",
    "        # for x,y in dataloader:\n",
    "        #     with torch.inference_mode():\n",
    "        #         model.eval()\n",
    "        #         o=model(x)[:,-1,:]\n",
    "        #         o0=o[list(range(len(x))),y]\n",
    "        #         o0=o0.cpu()\n",
    "        #         x=x.cpu()\n",
    "        #         for p,q in zip(o0,x):\n",
    "        #             A,B=int(q[0].item()),int(q[1].item())\n",
    "        #             oo[(A+B)%C][(A-B)%C]=p.item()\n",
    "        #         o[list(range(len(x))),y]=float(\"-inf\")\n",
    "        #         o1=o.topk(dim=-1,k=2).values.cpu()\n",
    "        #         print(o1)\n",
    "        #         for p,q in zip(o1,x):\n",
    "        #             A,B=int(q[0].item()),int(q[1].item())\n",
    "        #             oc[(A+B)%C][(A-B)%C]=p[0].item()\n",
    "        # use seaborn to plot the heatmap of oo\n",
    "        \n",
    "        run=result_modadd['run']\n",
    "        # oo=np.array(oc)\n",
    "        # dd=np.mean(np.std(oo,axis=0))/np.std(oo.flatten())\n",
    "        # #print('dd',dd)\n",
    "        # run.summary['distance_irrelevancy']=dd\n",
    "        # run.summary['logits']=oo\n",
    "        # mi,mx=np.min(oo),np.max(oo)\n",
    "        # oo=(oo-mi)/(mx-mi)\n",
    "        # run.summary['logits_normalized']=oo\n",
    "        # sns.heatmap(np.array(oo))\n",
    "        # sb=[]\n",
    "        # sx=[]\n",
    "        # sc=[]\n",
    "        # ss=[]\n",
    "        # for i in range(C):\n",
    "        #     s=oo[:,i]\n",
    "        #     sb.append(np.median(s))\n",
    "        #     ss.append(np.mean(s))\n",
    "        #     sx.append(np.std(oo[i]))\n",
    "        # print('std(med(col))',np.std(sb))\n",
    "        # print('mean(std(row))',np.mean(sx))\n",
    "        # run.summary['std_med_col']=np.std(sb)\n",
    "        # run.summary['mean_std_row']=np.mean(sx)\n",
    "        # run.summary['std_mean_col']=np.std(ss)\n",
    "        # run.summary['med_std_row']=np.median(sx)\n",
    "        path = root_path + f'/save/{experiment_name}'\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        model_name=os.path.join(root_path, f'{path}/model_{run_name}.pt')\n",
    "        model=result_modadd['model']\n",
    "        torch.save(model.state_dict(), model_name)\n",
    "        import json\n",
    "        config['func']=None\n",
    "        with open(os.path.join(root_path, f'{path}/config_{run_name}.json'),'w') as f:\n",
    "            json.dump(config,f,separators=(',\\n', ': '))\n",
    "        run.finish()\n",
    "    \n",
    "    # !python -m wandb offline"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12956.942106,
   "end_time": "2024-12-08T06:17:49.094203",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-08T02:41:52.152097",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
