{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b452dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T20:23:37.850823Z",
     "iopub.status.busy": "2024-12-14T20:23:37.850497Z",
     "iopub.status.idle": "2024-12-14T20:23:47.288179Z",
     "shell.execute_reply": "2024-12-14T20:23:47.287134Z"
    },
    "papermill": {
     "duration": 9.444343,
     "end_time": "2024-12-14T20:23:47.290256",
     "exception": false,
     "start_time": "2024-12-14T20:23:37.845913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\r\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: einops\r\n",
      "Successfully installed einops-0.8.0\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch==2.5.0 torchvision==0.20.0 torchaudio==2.5.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "# !pip install tqdm\n",
    "# !pip install matplotlib \n",
    "# !pip install plotly\n",
    "# !pip install pandas\n",
    "# !pip install wandb\n",
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b48c3bb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-14T20:23:47.297869Z",
     "iopub.status.busy": "2024-12-14T20:23:47.297599Z",
     "iopub.status.idle": "2024-12-14T20:23:54.411052Z",
     "shell.execute_reply": "2024-12-14T20:23:54.410370Z"
    },
    "papermill": {
     "duration": 7.119777,
     "end_time": "2024-12-14T20:23:54.413069",
     "exception": false,
     "start_time": "2024-12-14T20:23:47.293292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# adapted from https://colab.research.google.com/drive/1F6_1_cWXE5M7WocUcpQWp3v8z4b1jL20 (https://arxiv.org/abs/2301.05217), thanks!\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "import tqdm\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"colab\"\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from functools import *\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "# import comet_ml\n",
    "import wandb\n",
    "import itertools\n",
    "\n",
    "# find path of the project from the script\n",
    "root_path = '/kaggle/working'\n",
    "# from analysis.utils import extract_embeddings\n",
    "\n",
    "# 改成你的wandb key\n",
    "wandb.login(key='2b1626edceae9b68a67d66923587da64398da02c') \n",
    "# 改成你的wandb key\n",
    "\n",
    "class HookPoint(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fwd_hooks = []\n",
    "        self.bwd_hooks = []\n",
    "    def give_name(self, name):\n",
    "        self.name = name\n",
    "    def add_hook(self, hook, dir='fwd'):\n",
    "        def full_hook(module, module_input, module_output):\n",
    "            return hook(module_output, name=self.name)\n",
    "        if dir=='fwd':\n",
    "            handle = self.register_forward_hook(full_hook)\n",
    "            self.fwd_hooks.append(handle)\n",
    "        elif dir=='bwd':\n",
    "            handle = self.register_backward_hook(full_hook)\n",
    "            self.bwd_hooks.append(handle)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid direction {dir}\")\n",
    "    def remove_hooks(self, dir='fwd'):\n",
    "        if (dir=='fwd') or (dir=='both'):\n",
    "            for hook in self.fwd_hooks:\n",
    "                hook.remove()\n",
    "            self.fwd_hooks = []\n",
    "        if (dir=='bwd') or (dir=='both'):\n",
    "            for hook in self.bwd_hooks:\n",
    "                hook.remove()\n",
    "            self.bwd_hooks = []\n",
    "        if dir not in ['fwd', 'bwd', 'both']:\n",
    "            raise ValueError(f\"Invalid direction {dir}\")\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class Embed(nn.Module):\n",
    "    def __init__(self, d_vocab, d_model):\n",
    "        super().__init__()\n",
    "        self.W_E = nn.Parameter(torch.randn(d_model, d_vocab)/np.sqrt(d_model))\n",
    "    def forward(self, x):\n",
    "        return torch.einsum('dbp -> bpd', self.W_E[:, x])\n",
    "\n",
    "class Unembed(nn.Module):\n",
    "    def __init__(self, d_vocab, d_model):\n",
    "        super().__init__()\n",
    "        self.W_U = nn.Parameter(torch.randn(d_model, d_vocab)/np.sqrt(d_vocab))\n",
    "    def forward(self, x):\n",
    "        return (x @ self.W_U)\n",
    "\n",
    "# Positional Embeddings\n",
    "class PosEmbed(nn.Module):\n",
    "    def __init__(self, max_ctx, d_model):\n",
    "        super().__init__()\n",
    "        self.W_pos = nn.Parameter(torch.randn(max_ctx, d_model)/np.sqrt(d_model))\n",
    "    def forward(self, x):\n",
    "        return x+self.W_pos[:x.shape[-2]]\n",
    "\n",
    "# Attention\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_head, n_ctx, attn_coeff):\n",
    "        super().__init__()\n",
    "        self.W_K = nn.Parameter(torch.randn(num_heads, d_head, d_model)/np.sqrt(d_model))\n",
    "        self.W_Q = nn.Parameter(torch.randn(num_heads, d_head, d_model)/np.sqrt(d_model))\n",
    "        self.W_V = nn.Parameter(torch.randn(num_heads, d_head, d_model)/np.sqrt(d_model))\n",
    "        self.W_O = nn.Parameter(torch.randn(d_model, d_head * num_heads)/np.sqrt(d_model))\n",
    "        self.attn_coeff = attn_coeff\n",
    "        self.register_buffer('mask', torch.tril(torch.ones((n_ctx, n_ctx))))\n",
    "        self.d_head = d_head\n",
    "        self.hook_k = HookPoint()\n",
    "        self.hook_q = HookPoint()\n",
    "        self.hook_v = HookPoint()\n",
    "        self.hook_z = HookPoint()\n",
    "        self.hook_attn = HookPoint()\n",
    "        self.hook_attn_pre = HookPoint()\n",
    "\n",
    "    def forward(self, x):\n",
    "        k = self.hook_k(torch.einsum('ihd,bpd->biph', self.W_K, x))\n",
    "        q = self.hook_q(torch.einsum('ihd,bpd->biph', self.W_Q, x))\n",
    "        v = self.hook_v(torch.einsum('ihd,bpd->biph', self.W_V, x))\n",
    "        attn_scores_pre = torch.einsum('biph,biqh->biqp', k, q)\n",
    "        attn_scores_masked =attn_scores_pre\n",
    "        normalized = self.hook_attn_pre(attn_scores_masked/np.sqrt(self.d_head))\n",
    "        normalized = F.softmax(normalized, dim=-1)\n",
    "        attn_matrix = self.hook_attn(\n",
    "            normalized*self.attn_coeff+(1-self.attn_coeff))\n",
    "        z = self.hook_z(torch.einsum('biph,biqp->biqh', v, attn_matrix))\n",
    "        z_flat = einops.rearrange(z, 'b i q h -> b q (i h)')\n",
    "        out = torch.einsum('df,bqf->bqd', self.W_O, z_flat)\n",
    "        return out\n",
    "\n",
    "# +\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_model, d_mlp, act_type):\n",
    "        super().__init__()\n",
    "        self.W_in = nn.Parameter(torch.randn(d_mlp, d_model)/np.sqrt(d_mlp))\n",
    "        self.b_in = nn.Parameter(torch.zeros(d_mlp))\n",
    "        self.W_out = nn.Parameter(torch.randn(d_model, d_mlp)/np.sqrt(d_model))\n",
    "        self.b_out = nn.Parameter(torch.zeros(d_model))\n",
    "        self.act_type = act_type\n",
    "        # self.ln = LayerNorm(d_mlp, model=self.model)\n",
    "        self.hook_pre = HookPoint()\n",
    "        self.hook_post = HookPoint()\n",
    "        assert act_type in ['ReLU', 'GeLU', 'Tanh']\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hook_pre(torch.einsum('md,bpd->bpm', self.W_in, x) + self.b_in)\n",
    "        if self.act_type=='ReLU':\n",
    "            x = F.relu(x)\n",
    "        elif self.act_type=='GeLU':\n",
    "            x = F.gelu(x)\n",
    "        elif self.act_type=='Tanh':\n",
    "            x = F.tanh(x)\n",
    "        x = self.hook_post(x)\n",
    "#        return x\n",
    "        x = torch.einsum('dm,bpm->bpd', self.W_out, x) + self.b_out\n",
    "        return x\n",
    "\n",
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, d_model, act_type):\n",
    "        super().__init__()\n",
    "        self.W_in = nn.Parameter(torch.randn(d_model, d_model)/np.sqrt(d_model))\n",
    "        self.b_in = nn.Parameter(torch.zeros(d_model))\n",
    "        self.act_type = act_type\n",
    "        self.hook_pre = HookPoint()\n",
    "        self.hook_post = HookPoint()\n",
    "        assert act_type in ['ReLU', 'GeLU', 'Tanh']\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.einsum('md,bpd->bpm', self.W_in, self.hook_pre(x)) + self.b_in\n",
    "        if self.act_type=='ReLU':\n",
    "            x = F.relu(x)\n",
    "        elif self.act_type=='GeLU':\n",
    "            x = F.gelu(x)\n",
    "        elif self.act_type=='Tanh':\n",
    "            x = F.tanh(x)\n",
    "        x = self.hook_post(x)\n",
    "        return x\n",
    "        \n",
    "# Transformer Block\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, d_head, num_heads, n_ctx, act_type, attn_coeff):\n",
    "        super().__init__()\n",
    "        self.attn = Attention(d_model, num_heads, d_head, n_ctx, attn_coeff=attn_coeff)\n",
    "        self.mlp = MLP(d_model, d_model*4,act_type)\n",
    "        self.hook_attn_out = HookPoint()\n",
    "        self.hook_mlp_out = HookPoint()\n",
    "        self.hook_resid_pre = HookPoint()\n",
    "        self.hook_resid_mid = HookPoint()\n",
    "        self.hook_resid_post = HookPoint()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.hook_resid_mid(x + self.hook_attn_out(self.attn(self.hook_resid_pre(x))))\n",
    "        x = self.hook_resid_post(x + self.hook_mlp_out(self.mlp(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "# -\n",
    "\n",
    "# Full transformer\n",
    "class Transformer(nn.Module): # Model B\n",
    "    def __init__(self, num_layers, d_vocab, d_model, d_head, num_heads, n_ctx, act_type, attn_coeff, use_cache=False, use_ln=True):\n",
    "        super().__init__()\n",
    "        assert 0<=attn_coeff<=1\n",
    "        print('parameters', num_layers, d_vocab, d_model, d_head, num_heads, n_ctx, act_type, attn_coeff, use_cache, use_ln)\n",
    "        self.cache = {}\n",
    "        self.use_cache = use_cache\n",
    "\n",
    "        self.embed = Embed(d_vocab, d_model)\n",
    "        self.pos_embed = PosEmbed(n_ctx, d_model)\n",
    "        self.unembed = Unembed(d_vocab, d_model)\n",
    "        self.use_ln = use_ln\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(d_model, d_head, num_heads, n_ctx, act_type, attn_coeff) for i in range(num_layers)])\n",
    "\n",
    "        for name, module in self.named_modules():\n",
    "            if type(module)==HookPoint:\n",
    "                module.give_name(name)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.pos_embed(x)\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        x = self.unembed(x)\n",
    "        return x\n",
    "\n",
    "    def set_use_cache(self, use_cache):\n",
    "        self.use_cache = use_cache\n",
    "    \n",
    "    def hook_points(self):\n",
    "        return [module for name, module in self.named_modules() if 'hook' in name]\n",
    "\n",
    "    def remove_all_hooks(self):\n",
    "        for hp in self.hook_points():\n",
    "            hp.remove_hooks('fwd')\n",
    "            hp.remove_hooks('bwd')\n",
    "    \n",
    "    def cache_all(self, cache, incl_bwd=False):\n",
    "        # Caches all activations wrapped in a HookPoint\n",
    "        def save_hook(tensor, name):\n",
    "            cache[name] = tensor.detach()\n",
    "        def save_hook_back(tensor, name):\n",
    "            cache[name+'_grad'] = tensor[0].detach()\n",
    "        for hp in self.hook_points():\n",
    "            hp.add_hook(save_hook, 'fwd')\n",
    "            if incl_bwd:\n",
    "                hp.add_hook(save_hook_back, 'bwd')\n",
    "    \n",
    "    def parameters_norm(self):\n",
    "        # Returns the l2 norm of all parameters\n",
    "        return sum([torch.sum(p*p).item() for p in self.parameters()])**0.5\n",
    "    \n",
    "    def l2_norm(self):\n",
    "        # Returns the l2 norm of all parameters\n",
    "        return sum([torch.sum(p*p) for p in self.parameters()])\n",
    "    \n",
    "    def parameters_flattened(self):\n",
    "        # Returns all parameters as a single tensor\n",
    "        return torch.cat([p.view(-1) for p in self.parameters()]).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "class Linearformer(nn.Module): # Model A???\n",
    "    def __init__(self, num_layers, d_vocab, d_model, d_head, num_heads, n_ctx, act_type, attn_coeff, use_cache=False, use_ln=True):\n",
    "        super().__init__()\n",
    "        print('parameters(L)', num_layers, d_vocab, d_model, d_head, num_heads, n_ctx, act_type, attn_coeff, use_cache, use_ln)\n",
    "        self.cache = {}\n",
    "        self.use_cache = use_cache\n",
    "        self.attn_coeff = attn_coeff\n",
    "\n",
    "        self.embed = Embed(d_vocab, d_model//n_ctx)\n",
    "        # pos embed is being commented in original code\n",
    "        self.pos_embed = PosEmbed(n_ctx, d_model)\n",
    "        self.unembed = Unembed(d_vocab, d_model)\n",
    "        self.use_ln = use_ln\n",
    "        self.blocks = nn.ModuleList([MyLinear(d_model, act_type) for i in range(num_layers)])\n",
    "        self.padder = nn.ConstantPad1d((0,d_model%n_ctx),0)\n",
    "\n",
    "        for name, module in self.named_modules():\n",
    "            if type(module)==HookPoint:\n",
    "                module.give_name(name)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        #print(x.shape)\n",
    "        x = x.reshape(-1,1,x.shape[1]*x.shape[2])\n",
    "        #print(x.shape)\n",
    "        x = self.padder(x)\n",
    "        #print(x.shape)\n",
    "        #print(x.shape)\n",
    "        assert len(x.shape)==3 and x.shape[1:]==(1,d_model)\n",
    "        x = self.pos_embed(x)\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        x = self.unembed(x)\n",
    "        return x\n",
    "\n",
    "    def set_use_cache(self, use_cache):\n",
    "        self.use_cache = use_cache\n",
    "    \n",
    "    def hook_points(self):\n",
    "        return [module for name, module in self.named_modules() if 'hook' in name]\n",
    "\n",
    "    def remove_all_hooks(self):\n",
    "        for hp in self.hook_points():\n",
    "            hp.remove_hooks('fwd')\n",
    "            hp.remove_hooks('bwd')\n",
    "    \n",
    "    def cache_all(self, cache, incl_bwd=False):\n",
    "        # Caches all activations wrapped in a HookPoint\n",
    "        def save_hook(tensor, name):\n",
    "            cache[name] = tensor.detach()\n",
    "        def save_hook_back(tensor, name):\n",
    "            cache[name+'_grad'] = tensor[0].detach()\n",
    "        for hp in self.hook_points():\n",
    "            hp.add_hook(save_hook, 'fwd')\n",
    "            if incl_bwd:\n",
    "                hp.add_hook(save_hook_back, 'bwd')\n",
    "    \n",
    "    def parameters_norm(self):\n",
    "        # Returns the l2 norm of all parameters\n",
    "        return sum([torch.sum(p*p).item() for p in self.parameters()])**0.5\n",
    "    \n",
    "    def l2_norm(self):\n",
    "        # Returns the l2 norm of all parameters\n",
    "        return sum([torch.sum(p*p) for p in self.parameters()])\n",
    "    \n",
    "    def parameters_flattened(self):\n",
    "        # Returns all parameters as a single tensor\n",
    "        return torch.cat([p.view(-1) for p in self.parameters()]).detach().cpu().numpy()\n",
    "\n",
    "DEVICE='cuda'\n",
    "# DEVICE='cuda:'+str(random.randint(0,1))\n",
    "print(DEVICE)\n",
    "class MyAddDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, func, C, diff_vocab=False, eqn_sign=False):\n",
    "        self.func = func\n",
    "        dim = 2\n",
    "        self.dim = dim\n",
    "        self.C = C\n",
    "        self.inputs = []\n",
    "        self.outputs = []\n",
    "        self.vocab=C\n",
    "        if diff_vocab:\n",
    "            self.vocab*=2\n",
    "        if eqn_sign:\n",
    "            self.vocab+=1\n",
    "            self.dim+=1\n",
    "        self.vocab_out=0\n",
    "        for p in range(C**dim):\n",
    "            x = np.unravel_index(p, (C,)*dim)\n",
    "            o=self.func(x)\n",
    "            s=[x[0],x[1]]\n",
    "            if diff_vocab:\n",
    "                s[1]+=C\n",
    "            if eqn_sign:\n",
    "                s.append(self.vocab-1)\n",
    "            self.inputs.append(s)\n",
    "            self.outputs.append(o)\n",
    "            self.vocab_out=max(self.vocab_out, o+1)\n",
    "        if self.vocab_out!=C:\n",
    "            print(f'warning {self.vocab_out=} neq to {C=}')\n",
    "        self.inputs = torch.tensor(self.inputs, dtype=torch.long, device=DEVICE)\n",
    "        self.outputs = torch.tensor(self.outputs, dtype=torch.long, device=DEVICE)\n",
    "        # print(self.inputs,self.outputs)\n",
    "    def __len__(self):\n",
    "        return len(self.outputs)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.outputs[idx]\n",
    "\n",
    "def cross_entropy_high_precision(logits, labels):\n",
    "    # Shapes: batch x vocab, batch\n",
    "    # Cast logits to float64 because log_softmax has a float32 underflow on overly \n",
    "    # confident data and can only return multiples of 1.2e-7 (the smallest float x\n",
    "    # such that 1+x is different from 1 in float32). This leads to loss spikes \n",
    "    # and dodgy gradients\n",
    "    logprobs = F.log_softmax(logits.to(torch.float64), dim=-1)\n",
    "    prediction_logprobs = torch.gather(logprobs, index=labels[:, None], dim=-1)\n",
    "    loss = -torch.mean(prediction_logprobs)\n",
    "    return loss\n",
    "\n",
    "def run_experiment(config):\n",
    "    exp_name=config['name']\n",
    "    print('parsing func',config['funcs'])\n",
    "    config['func']=eval(config['funcs'])\n",
    "    #useLinear=config.get('use_linear',False)\n",
    "    full_dataset = MyAddDataSet(func=config['func'],C=config['C'],diff_vocab=config['diff_vocab'],eqn_sign=config['eqn_sign'])\n",
    "    model = Transformer(\n",
    "        num_layers=config.get('n_layers',1),\n",
    "        num_heads=config['n_heads'],\n",
    "        d_model=config['d_model'],\n",
    "        d_head=config.get('d_head',config['d_model']//config['n_heads']),\n",
    "        attn_coeff=config['attn_coeff'],\n",
    "        d_vocab=full_dataset.vocab,\n",
    "#        attention_dir=config.get('attention_dir','bidirectional'),\n",
    "        act_type=config.get('act_fn','relu'),\n",
    "        n_ctx=full_dataset.dim,\n",
    "#        normalization_type=None,\n",
    "    )\n",
    "    model.to(DEVICE)\n",
    "    train_frac = config['trainfrac']\n",
    "    train_size = int(config['frac'] * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "    if train_frac is not None:\n",
    "        new_train_size = int(train_frac * train_size)\n",
    "        remove_size = train_size - new_train_size\n",
    "        train_dataset, _ = torch.utils.data.random_split(train_dataset, [new_train_size, remove_size])\n",
    "    print('random split',len(train_dataset),len(test_dataset))\n",
    "    batch_size = config.get('batch_size',len(full_dataset))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    opt = optim.AdamW(model.parameters(),lr=config.get('lr',1e-3),weight_decay=config.get('weight_decay',1e-4),betas=(0.9,0.98))\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(opt, lambda step: min(step/10, 1)) # 10 epoch warmup\n",
    "    print(config.get('lr',1e-3),config.get('weight_decay',1e-4))\n",
    "    print(opt,scheduler)\n",
    "    losses=[]\n",
    "    accs=[]\n",
    "    losses_val=[]\n",
    "    accs_val=[]\n",
    "    norms=[]\n",
    "    loss_val=10\n",
    "    acc_val=0\n",
    "    stop=None\n",
    "    best_train_acc=0.\n",
    "    best_test_acc=0.\n",
    "    perfect_train_time=None\n",
    "    perfect_test_time=None\n",
    "\n",
    "    # modification start here\n",
    "    embeddings=[]\n",
    "    pbar = tqdm.tqdm(range(config.get('epoch',10000)))\n",
    "    gaps=[]\n",
    "    early_stop_a=2\n",
    "    early_stop_b=1\n",
    "    if config.get('early_stop',None) is not None:\n",
    "        early_stop_a, early_stop_b = config['early_stop']\n",
    "    early_stop_timer=0\n",
    "    #model.train()\n",
    "\n",
    "    run = wandb.init(reinit=True,config=config,project='modadd_longer')#,settings=wandb.Settings(start_method=\"spawn\"))\n",
    "    try:\n",
    "        for i in range(config.get('epoch',10000)):\n",
    "            def evaluation():\n",
    "                nonlocal best_test_acc\n",
    "                nonlocal perfect_test_time\n",
    "                nonlocal early_stop_timer\n",
    "                nonlocal early_stop_a\n",
    "                nonlocal early_stop_b\n",
    "                # evaluate on test set, return loss and accuracy\n",
    "                # with torch.inference_mode():\n",
    "                    #model.eval()\n",
    "                losses_eval=[]\n",
    "                accs_eval=[]\n",
    "                for inp,ans in test_loader:\n",
    "                    # print(inp.shape)\n",
    "                    out = model(inp)[:,-1,:]\n",
    "                    loss = cross_entropy_high_precision(out,ans)\n",
    "                    acc = torch.sum((out.argmax(dim=1)==ans).float())/len(ans)\n",
    "                    # print(inp,'test',out.argmax(dim=1),ans)\n",
    "#                    acc = (out.argmax(dim=1)==ans).float().mean()\n",
    "                    losses_eval.append(loss.item())\n",
    "                    accs_eval.append(acc.item())\n",
    "                    # print(loss,acc)\n",
    "                #print(losses_eval,accs_eval)\n",
    "                eval_loss, eval_acc = np.mean(losses_eval), np.mean(accs_eval)\n",
    "                best_test_acc = max(best_test_acc, eval_acc)\n",
    "                if eval_acc==1. and perfect_test_time is None:\n",
    "                    perfect_test_time = i\n",
    "                if eval_acc>=early_stop_a:\n",
    "                    early_stop_timer+=1\n",
    "                else:\n",
    "                    early_stop_timer=0\n",
    "                #print(eval_loss,eval_acc)\n",
    "                return eval_loss, eval_acc\n",
    "            if early_stop_timer>=early_stop_b:\n",
    "                break\n",
    "            for inp,ans in train_loader:\n",
    "                #print(inp.shape,inp.dtype)\n",
    "                # print(inp,'train')\n",
    "                #print(len(inp))\n",
    "                #model.train()\n",
    "                out = model(inp)[:,-1,:]\n",
    "                loss = cross_entropy_high_precision(out,ans)\n",
    "                loss_val, acc_val = evaluation()\n",
    "                #print(loss_val,acc_val)\n",
    "                loss.backward()\n",
    "                # clip gradients\n",
    "                #if config.get('clip',None) is not None:\n",
    "                #    nn.utils.clip_grad_norm_(model.parameters(), config['clip'])\n",
    "                opt.step()\n",
    "                scheduler.step()\n",
    "                opt.zero_grad()\n",
    "                acc = (out.argmax(dim=1)==ans).float().mean()\n",
    "                norm = sum([torch.sum(p*p).item() for p in model.parameters()])**0.5\n",
    "                #sum(p.norm()**2 for p in model.parameters()).sqrt().item()\n",
    "\n",
    "                # save every 10 epochs\n",
    "                if config['save_embeddings'] and i % 10 == 9:\n",
    "                    embeddings.append(extract_embeddings(model))\n",
    "                \n",
    "                losses.append(loss.item())\n",
    "                accs.append(acc.item())\n",
    "                losses_val.append(loss_val)\n",
    "                accs_val.append(acc_val)\n",
    "                norms.append(norm)\n",
    "\n",
    "                best_train_acc=max(best_train_acc,acc.item())\n",
    "                if acc.item()==1. and perfect_train_time is None:\n",
    "                    perfect_train_time = i\n",
    "                gaps.append(best_train_acc-best_test_acc)\n",
    "                # Store the final description instead of setting it during the loop\n",
    "                final_description = (\n",
    "                    f\"loss: {loss.item():.3f}, accm: {best_train_acc:.3f}, \"\n",
    "                    f\"vloss: {loss_val:.3f}, vaccm: {best_test_acc:.3f}, \"\n",
    "                    f\"norm: {norm:.3f}, acc: {acc.item():.3f}, vacc: {acc_val:.3f}\"\n",
    "                )\n",
    "                run.log({'training_loss': loss.item(),\n",
    "                'validation_loss': loss_val,\n",
    "                'training_accuracy': acc.item(),\n",
    "                'validation_accuracy': acc_val,\n",
    "                'parameter_norm': norm,\n",
    "                'best_train_accuracy': best_train_acc,\n",
    "                'best_test_accuracy': best_test_acc,\n",
    "                'generalization_gap': best_train_acc-best_test_acc,\n",
    "                'generalization_delay1': sum(gaps)})\n",
    "        print(final_description)\n",
    "    except KeyboardInterrupt:\n",
    "        print('Keyboard interrupt. Gracefully exiting...')\n",
    "        pass\n",
    "    print('Finished.')\n",
    "    generalization_gap=best_train_acc-best_test_acc\n",
    "    generalization_delay1=sum(gaps)\n",
    "    generalization_delay2=sum(max(t-(best_train_acc-best_test_acc),0) for t in gaps)\n",
    "    run.summary[\"generalization_delay2\"] = generalization_delay2\n",
    "    # run.finish()\n",
    "    return dict(\n",
    "        losses=losses,\n",
    "        accs=accs,\n",
    "        losses_val=losses_val,\n",
    "        accs_val=accs_val,\n",
    "        norms=norms,\n",
    "        model=model,\n",
    "        config=config,\n",
    "        generalization_gap=generalization_gap,\n",
    "        generalization_delay1=generalization_delay1,\n",
    "        generalization_delay2=generalization_delay2,\n",
    "        best_train_acc=best_train_acc,\n",
    "        best_test_acc=best_test_acc,\n",
    "        perfect_train_time=perfect_train_time,\n",
    "        perfect_test_time=perfect_test_time,\n",
    "        dataset=full_dataset,\n",
    "        embeddings=embeddings,\n",
    "        run=run\n",
    "    )\n",
    "\n",
    "import random\n",
    "import string\n",
    "import seaborn as sns\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22083d3",
   "metadata": {
    "papermill": {
     "duration": 0.002602,
     "end_time": "2024-12-14T20:23:54.418708",
     "exception": false,
     "start_time": "2024-12-14T20:23:54.416106",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### weight decay factor = 0.001, 0.1, 5, d_model =64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bc45285",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T20:23:54.425467Z",
     "iopub.status.busy": "2024-12-14T20:23:54.424825Z",
     "iopub.status.idle": "2024-12-14T20:23:54.429854Z",
     "shell.execute_reply": "2024-12-14T20:23:54.429021Z"
    },
    "papermill": {
     "duration": 0.010174,
     "end_time": "2024-12-14T20:23:54.431492",
     "exception": false,
     "start_time": "2024-12-14T20:23:54.421318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # C_list = [19,29,39,49,59,89,119,239]\n",
    "    \n",
    "# for count in range(100):\n",
    "#     # experiment_name = sys.argv[1] # 实验名字，等于保存模型的文件夹名字 ./save/{experiment_name}\n",
    "#     # modify_part = sys.argv[2] # 改动的部分，保存模型的命名的一部分\n",
    "#     # 随着loop变化的参数\n",
    "#     attn_coeff = count * 0.01 # 可以同步设置weight_decay改动\n",
    "#     weight_decay = 5.\n",
    "#     epoch = 20000 \n",
    "    \n",
    "#     C=59\n",
    "#     n_layers=1\n",
    "#     diff_vocab=0\n",
    "#     eqn_sign=0\n",
    "#     d_model=64 #用不同的d_model\n",
    "#     run_name = f\"d{d_model}_wd{weight_decay}_attn{attn_coeff:.6f}\"\n",
    "#     print(run_name)\n",
    "#     config=dict(\n",
    "#         name='modadd_'+str(C),\n",
    "#         funcs='lambda x: (x[0]+x[1])%'+str(C),\n",
    "#         C=C,\n",
    "#         n_heads=4,\n",
    "#         d_model=d_model,\n",
    "#         n_layers=n_layers,\n",
    "#         attention_dir='casual',\n",
    "#         # act_fn='GeLU' if random.randint(0,3)==0 else 'ReLU',\n",
    "#         act_fn='ReLU',\n",
    "#         epoch=epoch,\n",
    "#         batch_size=C*C,\n",
    "#         lr=1e-3,\n",
    "#         weight_decay=weight_decay,\n",
    "#         frac=0.8,\n",
    "#         trainfrac=None, # 训练集大小改变\n",
    "#         # should adjust the attn_coeff\n",
    "#         # attn_coeff=frac_coeff,\n",
    "#         attn_coeff=attn_coeff,\n",
    "#         runid=run_name,\n",
    "#         diff_vocab=diff_vocab,\n",
    "#         eqn_sign=eqn_sign,\n",
    "#         # use_linear=use_linear,\n",
    "#         save_embeddings=False,\n",
    "#     )\n",
    "#     result_modadd=run_experiment(config)\n",
    "    \n",
    "#     # save embeddings, see analysis.utils.extract_embeddings for details\n",
    "#     # if config['save_embeddings']:\n",
    "#     #     embed_path = f'result/model_{\"B\" if config[\"attn_coeff\"] else \"A\"}_embeddings.npz'\n",
    "#     #     np.savez_compressed(os.path.join(root_path, embed_path), result_modadd['embeddings'])\n",
    "    \n",
    "#     run=result_modadd['run']\n",
    "#     path = root_path + '/weight_decay'\n",
    "#     if not os.path.exists(path):\n",
    "#         os.makedirs(path)\n",
    "#     model_name=os.path.join(root_path, f'{path}/model_{run_name}.pt')\n",
    "#     model=result_modadd['model']\n",
    "#     torch.save(model.state_dict(), model_name)\n",
    "#     import json\n",
    "#     config['func']=None\n",
    "#     with open(os.path.join(root_path, f'{path}/config_{run_name}.json'),'w') as f:\n",
    "#         json.dump(config,f,separators=(',\\n', ': '))\n",
    "#     run.finish()\n",
    "    \n",
    "#     # !python -m wandb offline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d18b09a",
   "metadata": {
    "papermill": {
     "duration": 0.002478,
     "end_time": "2024-12-14T20:23:54.436789",
     "exception": false,
     "start_time": "2024-12-14T20:23:54.434311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### keep C = 59 but change the frac of training set, attention rate [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad1b2496",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T20:23:54.442918Z",
     "iopub.status.busy": "2024-12-14T20:23:54.442673Z",
     "iopub.status.idle": "2024-12-15T02:43:49.846311Z",
     "shell.execute_reply": "2024-12-15T02:43:49.845444Z"
    },
    "papermill": {
     "duration": 22795.408753,
     "end_time": "2024-12-15T02:43:49.848050",
     "exception": false,
     "start_time": "2024-12-14T20:23:54.439297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.4_0\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1113 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a26f177e1a0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myhanmowsnoo\u001b[0m (\u001b[33myhanmowsnoo-royal-institute-of-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_202355-jahvt2hj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msweet-water-830\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/jahvt2hj\u001b[0m\n",
      "  0%|          | 0/20000 [07:35<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.002, vaccm: 1.000, norm: 23.562, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▂██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▂▄▅▅███████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap ███▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm ██▇▇▆▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▁▁▁▁▇██████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss ▆█▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 1229.11134\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 1229.12288\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.56215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.00204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msweet-water-830\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/jahvt2hj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_202355-jahvt2hj/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.4_1\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1113 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605d624d0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_203132-iw53urru\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjolly-darkness-831\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/iw53urru\u001b[0m\n",
      "  0%|          | 0/20000 [07:49<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.825, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▁██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▁██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▇▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 510.88064\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 510.88841\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.82539\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mjolly-darkness-831\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/iw53urru\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_203132-iw53urru/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.4_2\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1113 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605d60070>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_203923-7e3l3qym\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhappy-river-832\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/7e3l3qym\u001b[0m\n",
      "  0%|          | 0/20000 [07:41<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.905, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▄▄▅████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap ███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm ███▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▁▃▇████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss ▆██▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 615.21541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 615.21572\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.90466\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mhappy-river-832\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/7e3l3qym\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_203923-7e3l3qym/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.4_3\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1113 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605cde6e0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_204706-pbberjh7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmisunderstood-shadow-833\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/pbberjh7\u001b[0m\n",
      "  0%|          | 0/20000 [07:41<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.006, vaccm: 1.000, norm: 23.408, acc: 1.000, vacc: 0.997\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▁██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▇▇█████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▇▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▇▆▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▇██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss ████▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 755.8208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 755.84883\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.40791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 0.99713\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.00627\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmisunderstood-shadow-833\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/pbberjh7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_204706-pbberjh7/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.4_4\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1113 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a25ca10a500>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_205449-abaoiq5u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhearty-shadow-834\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/abaoiq5u\u001b[0m\n",
      "  0%|          | 0/20000 [07:44<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.044, vaccm: 0.989, norm: 24.097, acc: 1.000, vacc: 0.987\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▁▁▁▁███████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▃▃▃▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap ███▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▇▇▆▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▁▁▁▂███████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 0.98852\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 1406.68194\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 1177.26396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0.01148\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 24.09739\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 0.98709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.04393\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mhearty-shadow-834\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/abaoiq5u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_205449-abaoiq5u/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.4_5\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1113 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a263f6011b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_210235-nkbg7t7n\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwise-dream-835\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/nkbg7t7n\u001b[0m\n",
      "  0%|          | 0/20000 [07:42<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.020, vaccm: 0.999, norm: 24.169, acc: 1.000, vacc: 0.994\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▁▁▂▇███████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap ██▇▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▆▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▂▇█████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▇▇▆▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 0.99857\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 771.90005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 743.22857\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0.00143\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 24.16892\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 0.99426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.02042\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mwise-dream-835\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/nkbg7t7n\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_210235-nkbg7t7n/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.4_6\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1113 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605d397e0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_211019-hgrh303x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhopeful-jazz-836\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/hgrh303x\u001b[0m\n",
      "  0%|          | 0/20000 [07:44<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.799, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▁▁▁▂▅██████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▂▃▄████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap ██▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▇▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▁▁▁▁▃▅█████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss ▇██▇▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 1444.83791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 1444.90317\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.79944\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mhopeful-jazz-836\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/hgrh303x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_211019-hgrh303x/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.4_7\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1113 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a263ff677c0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_211805-pcy394ju\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdazzling-mountain-837\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/pcy394ju\u001b[0m\n",
      "  0%|          | 0/20000 [07:40<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 22.554, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▂▆█████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▂▂▃████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █████▆▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm ██▇▇▆▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▂▂█████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss ██▇▇▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 1032.77136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 1032.77136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 22.55362\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdazzling-mountain-837\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/pcy394ju\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_211805-pcy394ju/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.4_8\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1113 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605d39fc0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_212547-dvwugqwm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mneat-voice-838\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/dvwugqwm\u001b[0m\n",
      "  0%|          | 0/20000 [07:41<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.039, vaccm: 0.997, norm: 23.430, acc: 1.000, vacc: 0.989\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▃▃▃▃▆██████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▁▂▂▅███████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm ██▇▆▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▁▃▄████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 0.99713\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 1684.58981\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 1627.2457\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0.00287\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.43001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 0.98852\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.03874\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mneat-voice-838\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/dvwugqwm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_212547-dvwugqwm/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.4_9\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1113 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605cdc670>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_213331-b3mqlwjx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstellar-leaf-839\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/b3mqlwjx\u001b[0m\n",
      "  0%|          | 0/20000 [07:38<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.012, vaccm: 1.000, norm: 23.628, acc: 1.000, vacc: 0.996\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▁▁▂▂███████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▆▆▇████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap ██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm ██▇▅▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▁▁▁▁▂▃█████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▇▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 1201.92681\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 1201.92681\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.628\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 0.9957\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.01158\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mstellar-leaf-839\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/b3mqlwjx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_213331-b3mqlwjx/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.5_0\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1392 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a263ffa4310>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_214111-h7zezne1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbreezy-oath-840\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/h7zezne1\u001b[0m\n",
      "  0%|          | 0/20000 [08:45<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.561, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▄██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▇▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm ██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▂██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 313.64556\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 313.64556\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.56096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mbreezy-oath-840\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/h7zezne1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_214111-h7zezne1/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.5_1\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1392 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2606e5f5e0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_214958-omj7ofmb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msuper-totem-841\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/omj7ofmb\u001b[0m\n",
      "  0%|          | 0/20000 [08:44<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 24.264, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▅██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▄▅▇▇███████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▇▆▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 436.73073\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 436.73073\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 24.2641\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 6e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msuper-totem-841\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/omj7ofmb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_214958-omj7ofmb/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.5_2\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1392 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605d623b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_215844-3h1dwgn5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvaliant-night-842\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/3h1dwgn5\u001b[0m\n",
      "  0%|          | 0/20000 [08:45<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.471, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▃██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▃▇█████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 383.78164\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 383.78164\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.47129\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 2e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mvaliant-night-842\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/3h1dwgn5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_215844-3h1dwgn5/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.5_3\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1392 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605cde560>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_220731-kj1rqdsx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdesert-night-843\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/kj1rqdsx\u001b[0m\n",
      "  0%|          | 0/20000 [08:48<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.001, vaccm: 1.000, norm: 23.764, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▁▇█████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▄██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 299.11271\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 299.11271\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.76395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.00054\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdesert-night-843\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/kj1rqdsx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_220731-kj1rqdsx/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.5_4\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1392 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605ccbac0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_221621-illkbylp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msweet-glitter-844\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/illkbylp\u001b[0m\n",
      "  0%|          | 0/20000 [08:47<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.001, vaccm: 1.000, norm: 24.768, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▇▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 423.20062\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 423.2063\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 24.76784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.00073\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msweet-glitter-844\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/illkbylp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_221621-illkbylp/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.5_5\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1392 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605d2bc40>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_222510-gpmqsbyc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mazure-star-845\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/gpmqsbyc\u001b[0m\n",
      "  0%|          | 0/20000 [08:42<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.504, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▁▃▅████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▆▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▇▅▅▅▄▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 310.0631\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 310.06946\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.50357\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mazure-star-845\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/gpmqsbyc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_222510-gpmqsbyc/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.5_6\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1392 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605cf8eb0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_223354-ivx5fx59\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmild-rain-846\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/ivx5fx59\u001b[0m\n",
      "  0%|          | 0/20000 [08:46<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 22.768, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▁▁▂████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▁██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap ▃█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm ███▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▃▇█████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 484.37366\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 484.37505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 22.76805\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.00011\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmild-rain-846\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/ivx5fx59\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_223354-ivx5fx59/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.5_7\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1392 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605ccbb20>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_224242-jvbsmj5u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlilac-dragon-847\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/jvbsmj5u\u001b[0m\n",
      "  0%|          | 0/20000 [08:46<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 22.976, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▁▇█████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▇██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap ██▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▇▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 402.68302\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 402.69294\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 22.97581\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mlilac-dragon-847\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/jvbsmj5u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_224242-jvbsmj5u/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.5_8\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1392 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a25c9d3ce20>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_225130-6rdad7eo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdashing-shape-848\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/6rdad7eo\u001b[0m\n",
      "  0%|          | 0/20000 [08:45<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.616, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▂▂█████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 444.40069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 444.43569\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.6156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdashing-shape-848\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/6rdad7eo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_225130-6rdad7eo/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.5_9\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1392 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2606e5ece0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_230017-88gujgpm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meager-pine-849\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/88gujgpm\u001b[0m\n",
      "  0%|          | 0/20000 [08:44<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.844, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▁██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▆██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▇██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap ▆██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▁▃█████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 508.32861\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 508.32861\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.84395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 4e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33meager-pine-849\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/88gujgpm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_230017-88gujgpm/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.6_0\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1670 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2606e47940>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_230903-tiamfebr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgolden-blaze-850\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/tiamfebr\u001b[0m\n",
      "  0%|          | 0/20000 [10:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.001, vaccm: 1.000, norm: 24.788, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▅▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▄██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 226.63544\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 226.63943\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 24.78773\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.00078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mgolden-blaze-850\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/tiamfebr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_230903-tiamfebr/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.6_1\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1670 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605cde560>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_231911-25v2fj6g\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrestful-voice-851\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/25v2fj6g\u001b[0m\n",
      "  0%|          | 0/20000 [10:07<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.767, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▄██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▇▇▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 214.42629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 214.42772\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.76663\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mrestful-voice-851\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/25v2fj6g\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_231911-25v2fj6g/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.6_2\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1670 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605d624d0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_232920-tshtyp3n\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mradiant-microwave-852\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/tshtyp3n\u001b[0m\n",
      "  0%|          | 0/20000 [10:07<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 24.113, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▁██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap ██▇▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▆▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss ▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 309.47339\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 309.47502\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 24.11349\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mradiant-microwave-852\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/tshtyp3n\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_232920-tshtyp3n/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.6_3\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1670 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605d39b40>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_233929-u3999kd3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mazure-forest-853\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/u3999kd3\u001b[0m\n",
      "  0%|          | 0/20000 [10:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.727, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▁██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap ▇█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▆▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ████▁▁▄█████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 205.98263\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 205.98657\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.72692\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mazure-forest-853\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/u3999kd3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_233929-u3999kd3/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.6_4\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1670 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605ca7040>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_234932-vgyxg093\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msmart-microwave-854\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/vgyxg093\u001b[0m\n",
      "  0%|          | 0/20000 [10:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.093, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm ██▇▅▅▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▆██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 234.86606\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 234.86606\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.09251\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msmart-microwave-854\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/vgyxg093\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_234932-vgyxg093/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.6_5\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1670 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a262bb32050>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241214_235939-hzij7996\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgolden-armadillo-855\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/hzij7996\u001b[0m\n",
      "  0%|          | 0/20000 [10:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.002, vaccm: 1.000, norm: 24.477, acc: 1.000, vacc: 0.999\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▆▄▄▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 293.04579\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 293.04579\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 24.47653\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 0.99857\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.00188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mgolden-armadillo-855\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/hzij7996\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241214_235939-hzij7996/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.6_6\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1670 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a25ca00d6c0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241215_000945-arvv7l5h\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdauntless-sun-856\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/arvv7l5h\u001b[0m\n",
      "  0%|          | 0/20000 [10:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.640, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▁██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▄██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm ██▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 205.58625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 205.58625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.63956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdauntless-sun-856\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/arvv7l5h\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241215_000945-arvv7l5h/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.6_7\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1670 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605d29d80>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241215_001952-3sjqn57s\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mclear-river-857\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/3sjqn57s\u001b[0m\n",
      "  0%|          | 0/20000 [10:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.544, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▁▂▄████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 265.53128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 265.536\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.54383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mclear-river-857\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/3sjqn57s\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241215_001952-3sjqn57s/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.6_8\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1670 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605d2a500>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241215_002958-dwsdqlcs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwobbly-disco-858\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/dwsdqlcs\u001b[0m\n",
      "  0%|          | 0/20000 [10:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.788, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▅██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 199.29681\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 199.3284\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.78778\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mwobbly-disco-858\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/dwsdqlcs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241215_002958-dwsdqlcs/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.6_9\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1670 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605d39510>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241215_004001-x53uyba7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvital-voice-859\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/x53uyba7\u001b[0m\n",
      "  0%|          | 0/20000 [10:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.515, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 199.99274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 200.00763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.51513\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mvital-voice-859\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/x53uyba7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241215_004001-x53uyba7/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.7_0\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1948 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605ca76d0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241215_005005-ul3jv6lm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdrawn-puddle-860\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/ul3jv6lm\u001b[0m\n",
      "  0%|          | 0/20000 [11:18<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.892, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▆▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 135.40469\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 135.40537\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.89209\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdrawn-puddle-860\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/ul3jv6lm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241215_005005-ul3jv6lm/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.7_1\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1948 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605ca4b20>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241215_010125-xdd9jpk3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mspring-wind-861\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/xdd9jpk3\u001b[0m\n",
      "  0%|          | 0/20000 [11:22<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 22.853, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▄██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▄██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 142.34392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 142.3781\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 22.85285\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mspring-wind-861\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/xdd9jpk3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241215_010125-xdd9jpk3/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.7_2\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1948 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a25c9d3f190>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241215_011249-e9pj31o1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhelpful-firefly-862\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/e9pj31o1\u001b[0m\n",
      "  0%|          | 0/20000 [11:20<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 22.673, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▅▅█████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 160.16516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 160.17969\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 22.67336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mhelpful-firefly-862\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/e9pj31o1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241215_011249-e9pj31o1/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.7_3\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1948 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a25c9d0d210>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241215_012411-4qoebhcm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcelestial-donkey-863\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/4qoebhcm\u001b[0m\n",
      "  0%|          | 0/20000 [11:19<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.808, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▃██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▁██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▇▆▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▂██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▅▄▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 128.83552\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 128.83995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.80845\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcelestial-donkey-863\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/4qoebhcm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241215_012411-4qoebhcm/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.7_4\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1948 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605cc8c10>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241215_013532-rp6puof2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcomfy-dust-864\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/rp6puof2\u001b[0m\n",
      "  0%|          | 0/20000 [11:23<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.439, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▃██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm ▇█▇▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 148.36787\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 148.42515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.43924\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcomfy-dust-864\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/rp6puof2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241215_013532-rp6puof2/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.7_5\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1948 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605cf9660>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241215_014657-atjge12y\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgenial-sun-865\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/atjge12y\u001b[0m\n",
      "  0%|          | 0/20000 [11:10<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.638, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▂██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▇██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm ██▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▇██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▆▅▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 201.36348\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 201.36348\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.63815\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mgenial-sun-865\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/atjge12y\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241215_014657-atjge12y/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.7_6\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1948 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605cfada0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241215_015809-62tkvu3u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mscarlet-hill-866\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/62tkvu3u\u001b[0m\n",
      "  0%|          | 0/20000 [11:29<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 22.620, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm ███▇▇▄▄▄▄▄▄▄▄▄▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ██▁▁▁▁██████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 94.29987\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 94.32072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 22.61965\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mscarlet-hill-866\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/62tkvu3u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241215_015809-62tkvu3u/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.7_7\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1948 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605d38370>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241215_020940-r43ab2n3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhelpful-leaf-867\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/r43ab2n3\u001b[0m\n",
      "  0%|          | 0/20000 [11:26<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 22.805, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁▅██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap ▄█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 169.29713\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 169.29713\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 22.80498\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mhelpful-leaf-867\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/r43ab2n3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241215_020940-r43ab2n3/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.7_8\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1948 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a26f177eec0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241215_022108-yq2dq5ez\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcrisp-fire-868\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/yq2dq5ez\u001b[0m\n",
      "  0%|          | 0/20000 [11:19<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 22.838, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁▅██████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▅▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 147.54303\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 147.54303\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 22.83766\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcrisp-fire-868\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/yq2dq5ez\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241215_022108-yq2dq5ez/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_frac0.7_9\n",
      "d=128\n",
      "parsing func lambda x: (x[0]+x[1])%59\n",
      "parameters 1 59 128 32 4 2 ReLU 0 False True\n",
      "random split 1948 697\n",
      "0.001 2.0\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.98)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.0\n",
      "    maximize: False\n",
      "    weight_decay: 2.0\n",
      ") <torch.optim.lr_scheduler.LambdaLR object at 0x7a2605cc9d80>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241215_023229-3ew66sxp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlikely-haze-869\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/3ew66sxp\u001b[0m\n",
      "  0%|          | 0/20000 [11:18<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000, accm: 1.000, vloss: 0.000, vaccm: 1.000, norm: 23.789, acc: 1.000, vacc: 1.000\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm █▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy ▁▁▁█████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best_test_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_train_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay1 173.10106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: generalization_delay2 173.13462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    generalization_gap 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        parameter_norm 23.78903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     training_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation_accuracy 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mlikely-haze-869\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer/runs/3ew66sxp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/yhanmowsnoo-royal-institute-of-technology/modadd_longer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241215_023229-3ew66sxp/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for attention_rate in [0]:\n",
    "    for trainfrac in [0.4,0.5,0.6,0.7]:\n",
    "        for i in range(10):\n",
    "            experiment_name = 'trainfrac'\n",
    "            modify_part = f'frac{trainfrac}'\n",
    "            # for use_linear in [False]: # false model B, true model A\n",
    "            # letters_and_numbers = string.ascii_lowercase + string.digits.replace('0', '')\n",
    "            #run_name = 'A_repr_'.join(random.choices(letters_and_numbers, k=10))\n",
    "            # run_name = 'A_repr_trans_'+str(count+1)\n",
    "            attn_coeff = attention_rate\n",
    "            epoch = 20000 #跑的时间实在太久\n",
    "            if attn_coeff == 0:\n",
    "                run_name = f\"A_{modify_part}_{i}\"\n",
    "            else:\n",
    "                run_name = f\"B_{modify_part}_{i}\"\n",
    "            print(run_name)\n",
    "            C=59\n",
    "            n_layers=1\n",
    "            # if random.randint(0,3):\n",
    "            #     n_layers=random.randint(1,4)\n",
    "            # frac_coeff=0.8\n",
    "            diff_vocab=0\n",
    "            eqn_sign=0\n",
    "            # if random.randint(0,4)==0:\n",
    "            #     diff_vocab=random.randint(0,1)\n",
    "            #     eqn_sign=random.randint(0,1)\n",
    "            d_model=128\n",
    "            # if random.randint(0,2)==0:\n",
    "            #     d_model=int(2**random.uniform(5,9))\n",
    "            print(f'd={d_model}')\n",
    "            config=dict(\n",
    "                name='modadd_59',\n",
    "                funcs='lambda x: (x[0]+x[1])%59',\n",
    "                C=C,\n",
    "                n_heads=4,\n",
    "                d_model=d_model,\n",
    "                n_layers=n_layers,\n",
    "                attention_dir='casual',\n",
    "                # act_fn='GeLU' if random.randint(0,3)==0 else 'ReLU',\n",
    "                act_fn='ReLU',\n",
    "                epoch=epoch,\n",
    "                batch_size=C*C,\n",
    "                lr=1e-3,\n",
    "                weight_decay=2.,\n",
    "                frac=0.8,\n",
    "                trainfrac=trainfrac,\n",
    "                # should adjust the attn_coeff\n",
    "                # attn_coeff=frac_coeff,\n",
    "                attn_coeff=attn_coeff,\n",
    "                runid=run_name,\n",
    "                diff_vocab=diff_vocab,\n",
    "                eqn_sign=eqn_sign,\n",
    "                # use_linear=use_linear,\n",
    "                save_embeddings=False,\n",
    "            )\n",
    "            result_modadd=run_experiment(config)\n",
    "        \n",
    "            # save embeddings, see analysis.utils.extract_embeddings for details\n",
    "            if config['save_embeddings']:\n",
    "                embed_path = f'result/model_{\"B\" if config[\"attn_coeff\"] else \"A\"}_embeddings.npz'\n",
    "                np.savez_compressed(os.path.join(root_path, embed_path), result_modadd['embeddings'])\n",
    "    \n",
    "            run=result_modadd['run']\n",
    "            path = root_path + f'/save/{experiment_name}'\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            model_name=os.path.join(root_path, f'{path}/model_{run_name}.pt')\n",
    "            model=result_modadd['model']\n",
    "            torch.save(model.state_dict(), model_name)\n",
    "            import json\n",
    "            config['func']=None\n",
    "            with open(os.path.join(root_path, f'{path}/config_{run_name}.json'),'w') as f:\n",
    "                json.dump(config,f,separators=(',\\n', ': '))\n",
    "            run.finish()\n",
    "    \n",
    "    # !python -m wandb offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28f95a6",
   "metadata": {
    "papermill": {
     "duration": 0.027825,
     "end_time": "2024-12-15T02:43:49.904930",
     "exception": false,
     "start_time": "2024-12-15T02:43:49.877105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22816.841538,
   "end_time": "2024-12-15T02:43:52.286850",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-14T20:23:35.445312",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
